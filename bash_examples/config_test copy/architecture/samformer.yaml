# @package _global_

model:
  type: 'samformer'
  retrain: true
  restart: false
ts:
  name: 'test'
  version: 1
  enrich: ['hour']
  use_covariates: true
  silly: False
  use_future_covariates: true
  silly: false
model_configs:

  hidden_size: 16
  use_revin: false
  loss_type: 'mse'
  optim: torch.optim.AdamW
  activation: nn.ReLU
  quantiles: [0.1,0.5,0.9]

train_config:
  batch_size: 64
  max_epochs: 2