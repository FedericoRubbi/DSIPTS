# @package _global_

model:
  type: 'timexer'
  retrain: true
  restart: false
ts:
  name: 'test'
  version: 1
  enrich: ['hour']
  use_covariates: true
  use_future_covariates: true
  silly: false

model_configs:
  use_classical_positional_encoder: true 
  emb_dim: 17
  reduction_mode: mean 
  d_model: 4
  n_head: 4
  dropout_rate: 0.1
  n_layer_decoder: 3
  d_ff: 512
  patch_len: 4
  optim: torch.optim.Adam
  persistence_weight: 0.010
  loss_type: 'l1'
  activation: torch.nn.ReLU
  quantiles: [0.1,0.5,0.9]
train_config:
  batch_size: 32
  max_epochs: 4
         