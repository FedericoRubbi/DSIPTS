<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>dsipts.models package &#8212; DSIPTS 1.1.9 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="_static/basic.css?v=b08954a9" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=27fed22d" />
    <script src="_static/documentation_options.js?v=7b68ca77"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="dsipts-models-package">
<h1>dsipts.models package<a class="headerlink" href="#dsipts-models-package" title="Link to this heading">¶</a></h1>
<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Link to this heading">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="dsipts.models.autoformer.html">dsipts.models.autoformer package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.autoformer.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.autoformer.html#module-dsipts.models.autoformer.layers">dsipts.models.autoformer.layers module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.AutoCorrelation"><code class="docutils literal notranslate"><span class="pre">AutoCorrelation</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.AutoCorrelation.forward"><code class="docutils literal notranslate"><span class="pre">AutoCorrelation.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.AutoCorrelation.time_delay_agg_full"><code class="docutils literal notranslate"><span class="pre">AutoCorrelation.time_delay_agg_full()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.AutoCorrelation.time_delay_agg_inference"><code class="docutils literal notranslate"><span class="pre">AutoCorrelation.time_delay_agg_inference()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.AutoCorrelation.time_delay_agg_training"><code class="docutils literal notranslate"><span class="pre">AutoCorrelation.time_delay_agg_training()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.AutoCorrelationLayer"><code class="docutils literal notranslate"><span class="pre">AutoCorrelationLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.AutoCorrelationLayer.forward"><code class="docutils literal notranslate"><span class="pre">AutoCorrelationLayer.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.Decoder"><code class="docutils literal notranslate"><span class="pre">Decoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.Decoder.forward"><code class="docutils literal notranslate"><span class="pre">Decoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.DecoderLayer"><code class="docutils literal notranslate"><span class="pre">DecoderLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.DecoderLayer.forward"><code class="docutils literal notranslate"><span class="pre">DecoderLayer.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.Encoder"><code class="docutils literal notranslate"><span class="pre">Encoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.Encoder.forward"><code class="docutils literal notranslate"><span class="pre">Encoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.EncoderLayer"><code class="docutils literal notranslate"><span class="pre">EncoderLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.EncoderLayer.forward"><code class="docutils literal notranslate"><span class="pre">EncoderLayer.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.PositionalEmbedding"><code class="docutils literal notranslate"><span class="pre">PositionalEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.PositionalEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">PositionalEmbedding.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.moving_avg"><code class="docutils literal notranslate"><span class="pre">moving_avg</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.moving_avg.forward"><code class="docutils literal notranslate"><span class="pre">moving_avg.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.my_Layernorm"><code class="docutils literal notranslate"><span class="pre">my_Layernorm</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.my_Layernorm.forward"><code class="docutils literal notranslate"><span class="pre">my_Layernorm.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.series_decomp"><code class="docutils literal notranslate"><span class="pre">series_decomp</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.autoformer.html#dsipts.models.autoformer.layers.series_decomp.forward"><code class="docutils literal notranslate"><span class="pre">series_decomp.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.autoformer.html#module-dsipts.models.autoformer">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dsipts.models.crossformer.html">dsipts.models.crossformer package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.crossformer.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.crossformer.html#module-dsipts.models.crossformer.attn">dsipts.models.crossformer.attn module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.crossformer.html#dsipts.models.crossformer.attn.AttentionLayer"><code class="docutils literal notranslate"><span class="pre">AttentionLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.crossformer.html#dsipts.models.crossformer.attn.AttentionLayer.forward"><code class="docutils literal notranslate"><span class="pre">AttentionLayer.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.crossformer.html#dsipts.models.crossformer.attn.FullAttention"><code class="docutils literal notranslate"><span class="pre">FullAttention</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.crossformer.html#dsipts.models.crossformer.attn.FullAttention.forward"><code class="docutils literal notranslate"><span class="pre">FullAttention.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.crossformer.html#dsipts.models.crossformer.attn.TwoStageAttentionLayer"><code class="docutils literal notranslate"><span class="pre">TwoStageAttentionLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.crossformer.html#dsipts.models.crossformer.attn.TwoStageAttentionLayer.forward"><code class="docutils literal notranslate"><span class="pre">TwoStageAttentionLayer.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.crossformer.html#module-dsipts.models.crossformer.cross_decoder">dsipts.models.crossformer.cross_decoder module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.crossformer.html#dsipts.models.crossformer.cross_decoder.Decoder"><code class="docutils literal notranslate"><span class="pre">Decoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.crossformer.html#dsipts.models.crossformer.cross_decoder.Decoder.forward"><code class="docutils literal notranslate"><span class="pre">Decoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.crossformer.html#dsipts.models.crossformer.cross_decoder.DecoderLayer"><code class="docutils literal notranslate"><span class="pre">DecoderLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.crossformer.html#dsipts.models.crossformer.cross_decoder.DecoderLayer.forward"><code class="docutils literal notranslate"><span class="pre">DecoderLayer.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.crossformer.html#module-dsipts.models.crossformer.cross_embed">dsipts.models.crossformer.cross_embed module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.crossformer.html#dsipts.models.crossformer.cross_embed.DSW_embedding"><code class="docutils literal notranslate"><span class="pre">DSW_embedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.crossformer.html#dsipts.models.crossformer.cross_embed.DSW_embedding.forward"><code class="docutils literal notranslate"><span class="pre">DSW_embedding.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.crossformer.html#module-dsipts.models.crossformer.cross_encoder">dsipts.models.crossformer.cross_encoder module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.crossformer.html#dsipts.models.crossformer.cross_encoder.Encoder"><code class="docutils literal notranslate"><span class="pre">Encoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.crossformer.html#dsipts.models.crossformer.cross_encoder.Encoder.forward"><code class="docutils literal notranslate"><span class="pre">Encoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.crossformer.html#dsipts.models.crossformer.cross_encoder.SegMerging"><code class="docutils literal notranslate"><span class="pre">SegMerging</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.crossformer.html#dsipts.models.crossformer.cross_encoder.SegMerging.forward"><code class="docutils literal notranslate"><span class="pre">SegMerging.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.crossformer.html#dsipts.models.crossformer.cross_encoder.scale_block"><code class="docutils literal notranslate"><span class="pre">scale_block</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.crossformer.html#dsipts.models.crossformer.cross_encoder.scale_block.forward"><code class="docutils literal notranslate"><span class="pre">scale_block.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.crossformer.html#module-dsipts.models.crossformer">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dsipts.models.d3vae.html">dsipts.models.d3vae package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.d3vae.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.d3vae.html#module-dsipts.models.d3vae.diffusion_process">dsipts.models.d3vae.diffusion_process module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.diffusion_process.GaussianDiffusion"><code class="docutils literal notranslate"><span class="pre">GaussianDiffusion</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.diffusion_process.GaussianDiffusion.log_prob"><code class="docutils literal notranslate"><span class="pre">GaussianDiffusion.log_prob()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.diffusion_process.GaussianDiffusion.p_losses"><code class="docutils literal notranslate"><span class="pre">GaussianDiffusion.p_losses()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.diffusion_process.GaussianDiffusion.q_sample"><code class="docutils literal notranslate"><span class="pre">GaussianDiffusion.q_sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.diffusion_process.GaussianDiffusion.q_sample_target"><code class="docutils literal notranslate"><span class="pre">GaussianDiffusion.q_sample_target()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.diffusion_process.default"><code class="docutils literal notranslate"><span class="pre">default()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.diffusion_process.extract"><code class="docutils literal notranslate"><span class="pre">extract()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.diffusion_process.get_beta_schedule"><code class="docutils literal notranslate"><span class="pre">get_beta_schedule()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.diffusion_process.noise_like"><code class="docutils literal notranslate"><span class="pre">noise_like()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.d3vae.html#module-dsipts.models.d3vae.embedding">dsipts.models.d3vae.embedding module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.embedding.DataEmbedding"><code class="docutils literal notranslate"><span class="pre">DataEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.embedding.DataEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">DataEmbedding.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.embedding.PositionalEmbedding"><code class="docutils literal notranslate"><span class="pre">PositionalEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.embedding.PositionalEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">PositionalEmbedding.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.embedding.TemporalEmbedding"><code class="docutils literal notranslate"><span class="pre">TemporalEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.embedding.TemporalEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">TemporalEmbedding.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.embedding.TokenEmbedding"><code class="docutils literal notranslate"><span class="pre">TokenEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.embedding.TokenEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">TokenEmbedding.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.d3vae.html#module-dsipts.models.d3vae.encoder">dsipts.models.d3vae.encoder module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.Cell"><code class="docutils literal notranslate"><span class="pre">Cell</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.Cell.forward"><code class="docutils literal notranslate"><span class="pre">Cell.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.Encoder"><code class="docutils literal notranslate"><span class="pre">Encoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.Encoder.decoder_output"><code class="docutils literal notranslate"><span class="pre">Encoder.decoder_output()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.Encoder.forward"><code class="docutils literal notranslate"><span class="pre">Encoder.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.Encoder.init_decoder_tower"><code class="docutils literal notranslate"><span class="pre">Encoder.init_decoder_tower()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.Encoder.init_encoder_tower"><code class="docutils literal notranslate"><span class="pre">Encoder.init_encoder_tower()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.Encoder.init_post_process"><code class="docutils literal notranslate"><span class="pre">Encoder.init_post_process()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.Encoder.init_pre_process"><code class="docutils literal notranslate"><span class="pre">Encoder.init_pre_process()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.Encoder.init_sampler"><code class="docutils literal notranslate"><span class="pre">Encoder.init_sampler()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.Normal"><code class="docutils literal notranslate"><span class="pre">Normal</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.Normal.kl"><code class="docutils literal notranslate"><span class="pre">Normal.kl()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.Normal.log_p"><code class="docutils literal notranslate"><span class="pre">Normal.log_p()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.Normal.sample"><code class="docutils literal notranslate"><span class="pre">Normal.sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.Normal.sample_given_eps"><code class="docutils literal notranslate"><span class="pre">Normal.sample_given_eps()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.NormalDecoder"><code class="docutils literal notranslate"><span class="pre">NormalDecoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.NormalDecoder.log_prob"><code class="docutils literal notranslate"><span class="pre">NormalDecoder.log_prob()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.NormalDecoder.sample"><code class="docutils literal notranslate"><span class="pre">NormalDecoder.sample()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.log_density_gaussian"><code class="docutils literal notranslate"><span class="pre">log_density_gaussian()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.sample_normal_jit"><code class="docutils literal notranslate"><span class="pre">sample_normal_jit()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.encoder.soft_clamp5"><code class="docutils literal notranslate"><span class="pre">soft_clamp5()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.d3vae.html#module-dsipts.models.d3vae.model">dsipts.models.d3vae.model module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.model.Discriminator"><code class="docutils literal notranslate"><span class="pre">Discriminator</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.model.Discriminator.forward"><code class="docutils literal notranslate"><span class="pre">Discriminator.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.model.denoise_net"><code class="docutils literal notranslate"><span class="pre">denoise_net</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.model.denoise_net.extract"><code class="docutils literal notranslate"><span class="pre">denoise_net.extract()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.model.denoise_net.forward"><code class="docutils literal notranslate"><span class="pre">denoise_net.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.model.diffusion_generate"><code class="docutils literal notranslate"><span class="pre">diffusion_generate</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.model.diffusion_generate.forward"><code class="docutils literal notranslate"><span class="pre">diffusion_generate.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.model.pred_net"><code class="docutils literal notranslate"><span class="pre">pred_net</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.model.pred_net.forward"><code class="docutils literal notranslate"><span class="pre">pred_net.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.d3vae.html#module-dsipts.models.d3vae.neural_operations">dsipts.models.d3vae.neural_operations module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.BNELUConv"><code class="docutils literal notranslate"><span class="pre">BNELUConv</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.BNELUConv.forward"><code class="docutils literal notranslate"><span class="pre">BNELUConv.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.BNSwishConv"><code class="docutils literal notranslate"><span class="pre">BNSwishConv</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.BNSwishConv.forward"><code class="docutils literal notranslate"><span class="pre">BNSwishConv.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.Conv2D"><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.Conv2D.forward"><code class="docutils literal notranslate"><span class="pre">Conv2D.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.Conv2D.normalize_weight"><code class="docutils literal notranslate"><span class="pre">Conv2D.normalize_weight()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.ConvBNSwish"><code class="docutils literal notranslate"><span class="pre">ConvBNSwish</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.ConvBNSwish.forward"><code class="docutils literal notranslate"><span class="pre">ConvBNSwish.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.DecCombinerCell"><code class="docutils literal notranslate"><span class="pre">DecCombinerCell</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.DecCombinerCell.forward"><code class="docutils literal notranslate"><span class="pre">DecCombinerCell.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.ELUConv"><code class="docutils literal notranslate"><span class="pre">ELUConv</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.ELUConv.forward"><code class="docutils literal notranslate"><span class="pre">ELUConv.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.EncCombinerCell"><code class="docutils literal notranslate"><span class="pre">EncCombinerCell</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.EncCombinerCell.forward"><code class="docutils literal notranslate"><span class="pre">EncCombinerCell.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.FactorizedReduce"><code class="docutils literal notranslate"><span class="pre">FactorizedReduce</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.FactorizedReduce.forward"><code class="docutils literal notranslate"><span class="pre">FactorizedReduce.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.Identity"><code class="docutils literal notranslate"><span class="pre">Identity</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.Identity.forward"><code class="docutils literal notranslate"><span class="pre">Identity.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.InvertedResidual"><code class="docutils literal notranslate"><span class="pre">InvertedResidual</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.InvertedResidual.forward"><code class="docutils literal notranslate"><span class="pre">InvertedResidual.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.SE"><code class="docutils literal notranslate"><span class="pre">SE</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.SE.forward"><code class="docutils literal notranslate"><span class="pre">SE.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.Swish"><code class="docutils literal notranslate"><span class="pre">Swish</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.Swish.forward"><code class="docutils literal notranslate"><span class="pre">Swish.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.SwishFN"><code class="docutils literal notranslate"><span class="pre">SwishFN</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.SwishFN.backward"><code class="docutils literal notranslate"><span class="pre">SwishFN.backward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.SwishFN.forward"><code class="docutils literal notranslate"><span class="pre">SwishFN.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.SyncBatchNorm"><code class="docutils literal notranslate"><span class="pre">SyncBatchNorm</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.SyncBatchNorm.forward"><code class="docutils literal notranslate"><span class="pre">SyncBatchNorm.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.SyncBatchNormSwish"><code class="docutils literal notranslate"><span class="pre">SyncBatchNormSwish</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.SyncBatchNormSwish.forward"><code class="docutils literal notranslate"><span class="pre">SyncBatchNormSwish.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.UpSample"><code class="docutils literal notranslate"><span class="pre">UpSample</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.UpSample.forward"><code class="docutils literal notranslate"><span class="pre">UpSample.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.act"><code class="docutils literal notranslate"><span class="pre">act()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.get_batchnorm"><code class="docutils literal notranslate"><span class="pre">get_batchnorm()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.get_skip_connection"><code class="docutils literal notranslate"><span class="pre">get_skip_connection()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.logit"><code class="docutils literal notranslate"><span class="pre">logit()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.norm"><code class="docutils literal notranslate"><span class="pre">norm()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.neural_operations.normalize_weight_jit"><code class="docutils literal notranslate"><span class="pre">normalize_weight_jit()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.d3vae.html#module-dsipts.models.d3vae.resnet">dsipts.models.d3vae.resnet module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.resnet.ConvMeanPool"><code class="docutils literal notranslate"><span class="pre">ConvMeanPool</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.resnet.ConvMeanPool.forward"><code class="docutils literal notranslate"><span class="pre">ConvMeanPool.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.resnet.MeanPoolConv"><code class="docutils literal notranslate"><span class="pre">MeanPoolConv</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.resnet.MeanPoolConv.forward"><code class="docutils literal notranslate"><span class="pre">MeanPoolConv.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.resnet.MyConvo2d"><code class="docutils literal notranslate"><span class="pre">MyConvo2d</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.resnet.MyConvo2d.forward"><code class="docutils literal notranslate"><span class="pre">MyConvo2d.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.resnet.Res12_Quadratic"><code class="docutils literal notranslate"><span class="pre">Res12_Quadratic</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.resnet.Res12_Quadratic.forward"><code class="docutils literal notranslate"><span class="pre">Res12_Quadratic.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.resnet.ResidualBlock"><code class="docutils literal notranslate"><span class="pre">ResidualBlock</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.resnet.ResidualBlock.forward"><code class="docutils literal notranslate"><span class="pre">ResidualBlock.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.resnet.Square"><code class="docutils literal notranslate"><span class="pre">Square</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.resnet.Square.forward"><code class="docutils literal notranslate"><span class="pre">Square.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.resnet.Swish"><code class="docutils literal notranslate"><span class="pre">Swish</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.resnet.Swish.forward"><code class="docutils literal notranslate"><span class="pre">Swish.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.resnet.weights_init"><code class="docutils literal notranslate"><span class="pre">weights_init()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.d3vae.html#module-dsipts.models.d3vae.utils">dsipts.models.d3vae.utils module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.utils.average_tensor"><code class="docutils literal notranslate"><span class="pre">average_tensor()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.utils.get_arch_cells"><code class="docutils literal notranslate"><span class="pre">get_arch_cells()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.utils.get_input_size"><code class="docutils literal notranslate"><span class="pre">get_input_size()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.utils.get_stride_for_cell_type"><code class="docutils literal notranslate"><span class="pre">get_stride_for_cell_type()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.d3vae.html#dsipts.models.d3vae.utils.groups_per_scale"><code class="docutils literal notranslate"><span class="pre">groups_per_scale()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.d3vae.html#module-dsipts.models.d3vae">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dsipts.models.duet.html">dsipts.models.duet package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.duet.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.duet.html#module-dsipts.models.duet.layers">dsipts.models.duet.layers module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.layers.Linear_extractor"><code class="docutils literal notranslate"><span class="pre">Linear_extractor</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.layers.Linear_extractor.encoder"><code class="docutils literal notranslate"><span class="pre">Linear_extractor.encoder()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.layers.Linear_extractor.forecast"><code class="docutils literal notranslate"><span class="pre">Linear_extractor.forecast()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.layers.Linear_extractor.forward"><code class="docutils literal notranslate"><span class="pre">Linear_extractor.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.layers.Linear_extractor_cluster"><code class="docutils literal notranslate"><span class="pre">Linear_extractor_cluster</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.layers.Linear_extractor_cluster.cv_squared"><code class="docutils literal notranslate"><span class="pre">Linear_extractor_cluster.cv_squared()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.layers.Linear_extractor_cluster.forward"><code class="docutils literal notranslate"><span class="pre">Linear_extractor_cluster.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.layers.Linear_extractor_cluster.noisy_top_k_gating"><code class="docutils literal notranslate"><span class="pre">Linear_extractor_cluster.noisy_top_k_gating()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.layers.RevIN"><code class="docutils literal notranslate"><span class="pre">RevIN</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.layers.RevIN.forward"><code class="docutils literal notranslate"><span class="pre">RevIN.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.layers.SparseDispatcher"><code class="docutils literal notranslate"><span class="pre">SparseDispatcher</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.layers.SparseDispatcher.combine"><code class="docutils literal notranslate"><span class="pre">SparseDispatcher.combine()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.layers.SparseDispatcher.dispatch"><code class="docutils literal notranslate"><span class="pre">SparseDispatcher.dispatch()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.layers.SparseDispatcher.expert_to_gates"><code class="docutils literal notranslate"><span class="pre">SparseDispatcher.expert_to_gates()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.layers.encoder"><code class="docutils literal notranslate"><span class="pre">encoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.layers.encoder.forward"><code class="docutils literal notranslate"><span class="pre">encoder.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.duet.html#module-dsipts.models.duet.masked">dsipts.models.duet.masked module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.masked.AttentionLayer"><code class="docutils literal notranslate"><span class="pre">AttentionLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.masked.AttentionLayer.forward"><code class="docutils literal notranslate"><span class="pre">AttentionLayer.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.masked.Encoder"><code class="docutils literal notranslate"><span class="pre">Encoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.masked.Encoder.forward"><code class="docutils literal notranslate"><span class="pre">Encoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.masked.EncoderLayer"><code class="docutils literal notranslate"><span class="pre">EncoderLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.masked.EncoderLayer.forward"><code class="docutils literal notranslate"><span class="pre">EncoderLayer.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.masked.FullAttention"><code class="docutils literal notranslate"><span class="pre">FullAttention</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.masked.FullAttention.forward"><code class="docutils literal notranslate"><span class="pre">FullAttention.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.masked.Mahalanobis_mask"><code class="docutils literal notranslate"><span class="pre">Mahalanobis_mask</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.masked.Mahalanobis_mask.bernoulli_gumbel_rsample"><code class="docutils literal notranslate"><span class="pre">Mahalanobis_mask.bernoulli_gumbel_rsample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.masked.Mahalanobis_mask.calculate_prob_distance"><code class="docutils literal notranslate"><span class="pre">Mahalanobis_mask.calculate_prob_distance()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.duet.html#dsipts.models.duet.masked.Mahalanobis_mask.forward"><code class="docutils literal notranslate"><span class="pre">Mahalanobis_mask.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.duet.html#module-dsipts.models.duet">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dsipts.models.informer.html">dsipts.models.informer package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.informer.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.informer.html#module-dsipts.models.informer.attn">dsipts.models.informer.attn module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.attn.AttentionLayer"><code class="docutils literal notranslate"><span class="pre">AttentionLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.attn.AttentionLayer.forward"><code class="docutils literal notranslate"><span class="pre">AttentionLayer.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.attn.FullAttention"><code class="docutils literal notranslate"><span class="pre">FullAttention</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.attn.FullAttention.forward"><code class="docutils literal notranslate"><span class="pre">FullAttention.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.attn.ProbAttention"><code class="docutils literal notranslate"><span class="pre">ProbAttention</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.attn.ProbAttention.forward"><code class="docutils literal notranslate"><span class="pre">ProbAttention.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.attn.ProbMask"><code class="docutils literal notranslate"><span class="pre">ProbMask</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.attn.ProbMask.mask"><code class="docutils literal notranslate"><span class="pre">ProbMask.mask</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.attn.TriangularCausalMask"><code class="docutils literal notranslate"><span class="pre">TriangularCausalMask</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.attn.TriangularCausalMask.mask"><code class="docutils literal notranslate"><span class="pre">TriangularCausalMask.mask</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.informer.html#module-dsipts.models.informer.decoder">dsipts.models.informer.decoder module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.decoder.Decoder"><code class="docutils literal notranslate"><span class="pre">Decoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.decoder.Decoder.forward"><code class="docutils literal notranslate"><span class="pre">Decoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.decoder.DecoderLayer"><code class="docutils literal notranslate"><span class="pre">DecoderLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.decoder.DecoderLayer.forward"><code class="docutils literal notranslate"><span class="pre">DecoderLayer.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.informer.html#module-dsipts.models.informer.embed">dsipts.models.informer.embed module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.embed.DataEmbedding"><code class="docutils literal notranslate"><span class="pre">DataEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.embed.DataEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">DataEmbedding.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.embed.FixedEmbedding"><code class="docutils literal notranslate"><span class="pre">FixedEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.embed.FixedEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">FixedEmbedding.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.embed.PositionalEmbedding"><code class="docutils literal notranslate"><span class="pre">PositionalEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.embed.PositionalEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">PositionalEmbedding.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.embed.TemporalEmbedding"><code class="docutils literal notranslate"><span class="pre">TemporalEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.embed.TemporalEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">TemporalEmbedding.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.embed.TimeFeatureEmbedding"><code class="docutils literal notranslate"><span class="pre">TimeFeatureEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.embed.TimeFeatureEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">TimeFeatureEmbedding.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.embed.TokenEmbedding"><code class="docutils literal notranslate"><span class="pre">TokenEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.embed.TokenEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">TokenEmbedding.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.informer.html#module-dsipts.models.informer.encoder">dsipts.models.informer.encoder module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.encoder.ConvLayer"><code class="docutils literal notranslate"><span class="pre">ConvLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.encoder.ConvLayer.forward"><code class="docutils literal notranslate"><span class="pre">ConvLayer.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.encoder.Encoder"><code class="docutils literal notranslate"><span class="pre">Encoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.encoder.Encoder.forward"><code class="docutils literal notranslate"><span class="pre">Encoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.encoder.EncoderLayer"><code class="docutils literal notranslate"><span class="pre">EncoderLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.encoder.EncoderLayer.forward"><code class="docutils literal notranslate"><span class="pre">EncoderLayer.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.encoder.EncoderStack"><code class="docutils literal notranslate"><span class="pre">EncoderStack</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.informer.html#dsipts.models.informer.encoder.EncoderStack.forward"><code class="docutils literal notranslate"><span class="pre">EncoderStack.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.informer.html#module-dsipts.models.informer">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dsipts.models.itransformer.html">dsipts.models.itransformer package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.itransformer.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.itransformer.html#module-dsipts.models.itransformer.Embed">dsipts.models.itransformer.Embed module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Embed.DataEmbedding"><code class="docutils literal notranslate"><span class="pre">DataEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Embed.DataEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">DataEmbedding.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Embed.DataEmbedding_inverted"><code class="docutils literal notranslate"><span class="pre">DataEmbedding_inverted</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Embed.DataEmbedding_inverted.forward"><code class="docutils literal notranslate"><span class="pre">DataEmbedding_inverted.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Embed.FixedEmbedding"><code class="docutils literal notranslate"><span class="pre">FixedEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Embed.FixedEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">FixedEmbedding.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Embed.PositionalEmbedding"><code class="docutils literal notranslate"><span class="pre">PositionalEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Embed.PositionalEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">PositionalEmbedding.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Embed.TemporalEmbedding"><code class="docutils literal notranslate"><span class="pre">TemporalEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Embed.TemporalEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">TemporalEmbedding.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Embed.TimeFeatureEmbedding"><code class="docutils literal notranslate"><span class="pre">TimeFeatureEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Embed.TimeFeatureEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">TimeFeatureEmbedding.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Embed.TokenEmbedding"><code class="docutils literal notranslate"><span class="pre">TokenEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Embed.TokenEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">TokenEmbedding.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.itransformer.html#module-dsipts.models.itransformer.SelfAttention_Family">dsipts.models.itransformer.SelfAttention_Family module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.SelfAttention_Family.AttentionLayer"><code class="docutils literal notranslate"><span class="pre">AttentionLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.SelfAttention_Family.AttentionLayer.forward"><code class="docutils literal notranslate"><span class="pre">AttentionLayer.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.SelfAttention_Family.FlashAttention"><code class="docutils literal notranslate"><span class="pre">FlashAttention</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.SelfAttention_Family.FlashAttention.flash_attention_forward"><code class="docutils literal notranslate"><span class="pre">FlashAttention.flash_attention_forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.SelfAttention_Family.FlashAttention.forward"><code class="docutils literal notranslate"><span class="pre">FlashAttention.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.SelfAttention_Family.FlowAttention"><code class="docutils literal notranslate"><span class="pre">FlowAttention</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.SelfAttention_Family.FlowAttention.forward"><code class="docutils literal notranslate"><span class="pre">FlowAttention.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.SelfAttention_Family.FlowAttention.kernel_method"><code class="docutils literal notranslate"><span class="pre">FlowAttention.kernel_method()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.SelfAttention_Family.FullAttention"><code class="docutils literal notranslate"><span class="pre">FullAttention</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.SelfAttention_Family.FullAttention.forward"><code class="docutils literal notranslate"><span class="pre">FullAttention.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.SelfAttention_Family.ProbAttention"><code class="docutils literal notranslate"><span class="pre">ProbAttention</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.SelfAttention_Family.ProbAttention.forward"><code class="docutils literal notranslate"><span class="pre">ProbAttention.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.SelfAttention_Family.ProbMask"><code class="docutils literal notranslate"><span class="pre">ProbMask</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.SelfAttention_Family.ProbMask.mask"><code class="docutils literal notranslate"><span class="pre">ProbMask.mask</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.SelfAttention_Family.TriangularCausalMask"><code class="docutils literal notranslate"><span class="pre">TriangularCausalMask</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.SelfAttention_Family.TriangularCausalMask.mask"><code class="docutils literal notranslate"><span class="pre">TriangularCausalMask.mask</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.itransformer.html#module-dsipts.models.itransformer.Transformer_EncDec">dsipts.models.itransformer.Transformer_EncDec module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Transformer_EncDec.ConvLayer"><code class="docutils literal notranslate"><span class="pre">ConvLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Transformer_EncDec.ConvLayer.forward"><code class="docutils literal notranslate"><span class="pre">ConvLayer.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Transformer_EncDec.Decoder"><code class="docutils literal notranslate"><span class="pre">Decoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Transformer_EncDec.Decoder.forward"><code class="docutils literal notranslate"><span class="pre">Decoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Transformer_EncDec.DecoderLayer"><code class="docutils literal notranslate"><span class="pre">DecoderLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Transformer_EncDec.DecoderLayer.forward"><code class="docutils literal notranslate"><span class="pre">DecoderLayer.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Transformer_EncDec.Encoder"><code class="docutils literal notranslate"><span class="pre">Encoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Transformer_EncDec.Encoder.forward"><code class="docutils literal notranslate"><span class="pre">Encoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Transformer_EncDec.EncoderLayer"><code class="docutils literal notranslate"><span class="pre">EncoderLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.itransformer.html#dsipts.models.itransformer.Transformer_EncDec.EncoderLayer.forward"><code class="docutils literal notranslate"><span class="pre">EncoderLayer.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.itransformer.html#module-dsipts.models.itransformer">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dsipts.models.patchtst.html">dsipts.models.patchtst package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.patchtst.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.patchtst.html#module-dsipts.models.patchtst.layers">dsipts.models.patchtst.layers module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.Coord1dPosEncoding"><code class="docutils literal notranslate"><span class="pre">Coord1dPosEncoding()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.Coord2dPosEncoding"><code class="docutils literal notranslate"><span class="pre">Coord2dPosEncoding()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.Flatten_Head"><code class="docutils literal notranslate"><span class="pre">Flatten_Head</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.Flatten_Head.forward"><code class="docutils literal notranslate"><span class="pre">Flatten_Head.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.PatchTST_backbone"><code class="docutils literal notranslate"><span class="pre">PatchTST_backbone</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.PatchTST_backbone.create_pretrain_head"><code class="docutils literal notranslate"><span class="pre">PatchTST_backbone.create_pretrain_head()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.PatchTST_backbone.forward"><code class="docutils literal notranslate"><span class="pre">PatchTST_backbone.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.PositionalEncoding"><code class="docutils literal notranslate"><span class="pre">PositionalEncoding()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.RevIN"><code class="docutils literal notranslate"><span class="pre">RevIN</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.RevIN.forward"><code class="docutils literal notranslate"><span class="pre">RevIN.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.SinCosPosEncoding"><code class="docutils literal notranslate"><span class="pre">SinCosPosEncoding()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.TSTEncoder"><code class="docutils literal notranslate"><span class="pre">TSTEncoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.TSTEncoder.forward"><code class="docutils literal notranslate"><span class="pre">TSTEncoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.TSTEncoderLayer"><code class="docutils literal notranslate"><span class="pre">TSTEncoderLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.TSTEncoderLayer.forward"><code class="docutils literal notranslate"><span class="pre">TSTEncoderLayer.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.TSTiEncoder"><code class="docutils literal notranslate"><span class="pre">TSTiEncoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.TSTiEncoder.forward"><code class="docutils literal notranslate"><span class="pre">TSTiEncoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.Transpose"><code class="docutils literal notranslate"><span class="pre">Transpose</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.Transpose.forward"><code class="docutils literal notranslate"><span class="pre">Transpose.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.moving_avg"><code class="docutils literal notranslate"><span class="pre">moving_avg</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.moving_avg.forward"><code class="docutils literal notranslate"><span class="pre">moving_avg.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.positional_encoding"><code class="docutils literal notranslate"><span class="pre">positional_encoding()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.series_decomp"><code class="docutils literal notranslate"><span class="pre">series_decomp</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.patchtst.html#dsipts.models.patchtst.layers.series_decomp.forward"><code class="docutils literal notranslate"><span class="pre">series_decomp.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.patchtst.html#module-dsipts.models.patchtst">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dsipts.models.samformer.html">dsipts.models.samformer package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.samformer.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.samformer.html#module-dsipts.models.samformer.utils">dsipts.models.samformer.utils module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.samformer.html#dsipts.models.samformer.utils.RevIN"><code class="docutils literal notranslate"><span class="pre">RevIN</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.samformer.html#dsipts.models.samformer.utils.RevIN.forward"><code class="docutils literal notranslate"><span class="pre">RevIN.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.samformer.html#dsipts.models.samformer.utils.SAM"><code class="docutils literal notranslate"><span class="pre">SAM</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.samformer.html#dsipts.models.samformer.utils.SAM.first_step"><code class="docutils literal notranslate"><span class="pre">SAM.first_step()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.samformer.html#dsipts.models.samformer.utils.SAM.load_state_dict"><code class="docutils literal notranslate"><span class="pre">SAM.load_state_dict()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.samformer.html#dsipts.models.samformer.utils.SAM.second_step"><code class="docutils literal notranslate"><span class="pre">SAM.second_step()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.samformer.html#dsipts.models.samformer.utils.SAM.step"><code class="docutils literal notranslate"><span class="pre">SAM.step()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.samformer.html#dsipts.models.samformer.utils.scaled_dot_product_attention"><code class="docutils literal notranslate"><span class="pre">scaled_dot_product_attention()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.samformer.html#module-dsipts.models.samformer">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dsipts.models.tft.html">dsipts.models.tft package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.tft.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.tft.html#module-dsipts.models.tft.sub_nn">dsipts.models.tft.sub_nn module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.tft.html#dsipts.models.tft.sub_nn.GLU"><code class="docutils literal notranslate"><span class="pre">GLU</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.tft.html#dsipts.models.tft.sub_nn.GLU.forward"><code class="docutils literal notranslate"><span class="pre">GLU.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.tft.html#dsipts.models.tft.sub_nn.GRN"><code class="docutils literal notranslate"><span class="pre">GRN</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.tft.html#dsipts.models.tft.sub_nn.GRN.forward"><code class="docutils literal notranslate"><span class="pre">GRN.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.tft.html#dsipts.models.tft.sub_nn.InterpretableMultiHead"><code class="docutils literal notranslate"><span class="pre">InterpretableMultiHead</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.tft.html#dsipts.models.tft.sub_nn.InterpretableMultiHead.forward"><code class="docutils literal notranslate"><span class="pre">InterpretableMultiHead.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.tft.html#dsipts.models.tft.sub_nn.LSTM_Model"><code class="docutils literal notranslate"><span class="pre">LSTM_Model</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.tft.html#dsipts.models.tft.sub_nn.LSTM_Model.forward"><code class="docutils literal notranslate"><span class="pre">LSTM_Model.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.tft.html#dsipts.models.tft.sub_nn.ResidualConnection"><code class="docutils literal notranslate"><span class="pre">ResidualConnection</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.tft.html#dsipts.models.tft.sub_nn.ResidualConnection.forward"><code class="docutils literal notranslate"><span class="pre">ResidualConnection.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.tft.html#dsipts.models.tft.sub_nn.embedding_cat_variables"><code class="docutils literal notranslate"><span class="pre">embedding_cat_variables</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.tft.html#dsipts.models.tft.sub_nn.embedding_cat_variables.forward"><code class="docutils literal notranslate"><span class="pre">embedding_cat_variables.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.tft.html#dsipts.models.tft.sub_nn.embedding_cat_variables.get_cat_n_embd"><code class="docutils literal notranslate"><span class="pre">embedding_cat_variables.get_cat_n_embd()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.tft.html#dsipts.models.tft.sub_nn.embedding_cat_variables.get_is_fut"><code class="docutils literal notranslate"><span class="pre">embedding_cat_variables.get_is_fut()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.tft.html#dsipts.models.tft.sub_nn.embedding_cat_variables.get_pos_fut"><code class="docutils literal notranslate"><span class="pre">embedding_cat_variables.get_pos_fut()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.tft.html#dsipts.models.tft.sub_nn.embedding_cat_variables.get_pos_seq"><code class="docutils literal notranslate"><span class="pre">embedding_cat_variables.get_pos_seq()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.tft.html#module-dsipts.models.tft">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dsipts.models.timexer.html">dsipts.models.timexer package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.timexer.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.timexer.html#module-dsipts.models.timexer.Layers">dsipts.models.timexer.Layers module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.timexer.html#dsipts.models.timexer.Layers.EnEmbedding"><code class="docutils literal notranslate"><span class="pre">EnEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.timexer.html#dsipts.models.timexer.Layers.EnEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">EnEmbedding.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.timexer.html#dsipts.models.timexer.Layers.Encoder"><code class="docutils literal notranslate"><span class="pre">Encoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.timexer.html#dsipts.models.timexer.Layers.Encoder.forward"><code class="docutils literal notranslate"><span class="pre">Encoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.timexer.html#dsipts.models.timexer.Layers.EncoderLayer"><code class="docutils literal notranslate"><span class="pre">EncoderLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.timexer.html#dsipts.models.timexer.Layers.EncoderLayer.forward"><code class="docutils literal notranslate"><span class="pre">EncoderLayer.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.timexer.html#dsipts.models.timexer.Layers.FlattenHead"><code class="docutils literal notranslate"><span class="pre">FlattenHead</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.timexer.html#dsipts.models.timexer.Layers.FlattenHead.forward"><code class="docutils literal notranslate"><span class="pre">FlattenHead.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.timexer.html#dsipts.models.timexer.Layers.PositionalEmbedding"><code class="docutils literal notranslate"><span class="pre">PositionalEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.timexer.html#dsipts.models.timexer.Layers.PositionalEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">PositionalEmbedding.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.timexer.html#module-dsipts.models.timexer">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dsipts.models.ttm.html">dsipts.models.ttm package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.ttm.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.ttm.html#module-dsipts.models.ttm.configuration_tinytimemixer">dsipts.models.ttm.configuration_tinytimemixer module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.configuration_tinytimemixer.TinyTimeMixerConfig"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerConfig</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.configuration_tinytimemixer.TinyTimeMixerConfig.attribute_map"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerConfig.attribute_map</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.configuration_tinytimemixer.TinyTimeMixerConfig.check_and_init_preprocessing"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerConfig.check_and_init_preprocessing()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.configuration_tinytimemixer.TinyTimeMixerConfig.model_type"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerConfig.model_type</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.ttm.html#module-dsipts.models.ttm.consts">dsipts.models.ttm.consts module</a></li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.ttm.html#module-dsipts.models.ttm.modeling_tinytimemixer">dsipts.models.ttm.modeling_tinytimemixer module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.FeatureMixerBlock"><code class="docutils literal notranslate"><span class="pre">FeatureMixerBlock</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.FeatureMixerBlock.forward"><code class="docutils literal notranslate"><span class="pre">FeatureMixerBlock.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.ForecastChannelHeadMixer"><code class="docutils literal notranslate"><span class="pre">ForecastChannelHeadMixer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.ForecastChannelHeadMixer.forward"><code class="docutils literal notranslate"><span class="pre">ForecastChannelHeadMixer.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.PatchMixerBlock"><code class="docutils literal notranslate"><span class="pre">PatchMixerBlock</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.PatchMixerBlock.forward"><code class="docutils literal notranslate"><span class="pre">PatchMixerBlock.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.PinballLoss"><code class="docutils literal notranslate"><span class="pre">PinballLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.PinballLoss.forward"><code class="docutils literal notranslate"><span class="pre">PinballLoss.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.SampleTinyTimeMixerPredictionOutput"><code class="docutils literal notranslate"><span class="pre">SampleTinyTimeMixerPredictionOutput</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.SampleTinyTimeMixerPredictionOutput.sequences"><code class="docutils literal notranslate"><span class="pre">SampleTinyTimeMixerPredictionOutput.sequences</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerAdaptivePatchingBlock"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerAdaptivePatchingBlock</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerAdaptivePatchingBlock.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerAdaptivePatchingBlock.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerAttention"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerAttention</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerAttention.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerAttention.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerBatchNorm"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerBatchNorm</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerBatchNorm.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerBatchNorm.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerBlock"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerBlock</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerBlock.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerBlock.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerCategoricalEmbeddingLayer"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerCategoricalEmbeddingLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerCategoricalEmbeddingLayer.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerCategoricalEmbeddingLayer.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerChannelFeatureMixerBlock"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerChannelFeatureMixerBlock</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerChannelFeatureMixerBlock.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerChannelFeatureMixerBlock.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerDecoder"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerDecoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerDecoder.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerDecoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerEncoder"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerEncoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerEncoder.config_class"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerEncoder.config_class</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerEncoder.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerEncoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerEncoderOutput"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerEncoderOutput</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerEncoderOutput.hidden_states"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerEncoderOutput.hidden_states</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerEncoderOutput.last_hidden_state"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerEncoderOutput.last_hidden_state</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerForMaskedPrediction"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerForMaskedPrediction</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerForMaskedPrediction.config_class"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerForMaskedPrediction.config_class</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerForMaskedPrediction.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerForMaskedPrediction.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerForPrediction"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerForPrediction</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerForPrediction.config_class"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerForPrediction.config_class</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerForPrediction.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerForPrediction.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerForPrediction.generate"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerForPrediction.generate()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerForPredictionHead"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerForPredictionHead</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerForPredictionHead.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerForPredictionHead.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerForPredictionOutput"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerForPredictionOutput</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerForPredictionOutput.backbone_hidden_state"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerForPredictionOutput.backbone_hidden_state</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerForPredictionOutput.decoder_hidden_state"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerForPredictionOutput.decoder_hidden_state</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerForPredictionOutput.hidden_states"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerForPredictionOutput.hidden_states</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerForPredictionOutput.loc"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerForPredictionOutput.loc</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerForPredictionOutput.loss"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerForPredictionOutput.loss</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerForPredictionOutput.prediction_outputs"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerForPredictionOutput.prediction_outputs</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerForPredictionOutput.scale"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerForPredictionOutput.scale</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerGatedAttention"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerGatedAttention</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerGatedAttention.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerGatedAttention.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerLayer"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerLayer.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerLayer.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerMLP"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerMLP</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerMLP.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerMLP.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerMeanScaler"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerMeanScaler</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerMeanScaler.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerMeanScaler.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerModel"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerModel</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerModel.config_class"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerModel.config_class</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerModel.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerModel.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerModelOutput"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerModelOutput</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerModelOutput.hidden_states"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerModelOutput.hidden_states</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerModelOutput.last_hidden_state"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerModelOutput.last_hidden_state</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerModelOutput.loc"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerModelOutput.loc</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerModelOutput.patch_input"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerModelOutput.patch_input</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerModelOutput.scale"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerModelOutput.scale</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerNOPScaler"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerNOPScaler</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerNOPScaler.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerNOPScaler.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerNormLayer"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerNormLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerNormLayer.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerNormLayer.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerPatchify"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerPatchify</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerPatchify.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerPatchify.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerPositionalEncoding"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerPositionalEncoding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerPositionalEncoding.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerPositionalEncoding.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerPreTrainedModel"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerPreTrainedModel</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerPreTrainedModel.base_model_prefix"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerPreTrainedModel.base_model_prefix</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerPreTrainedModel.config_class"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerPreTrainedModel.config_class</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerPreTrainedModel.main_input_name"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerPreTrainedModel.main_input_name</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerPreTrainedModel.supports_gradient_checkpointing"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerPreTrainedModel.supports_gradient_checkpointing</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerStdScaler"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerStdScaler</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.TinyTimeMixerStdScaler.forward"><code class="docutils literal notranslate"><span class="pre">TinyTimeMixerStdScaler.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.nll"><code class="docutils literal notranslate"><span class="pre">nll()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.modeling_tinytimemixer.weighted_average"><code class="docutils literal notranslate"><span class="pre">weighted_average()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.ttm.html#module-dsipts.models.ttm.utils">dsipts.models.ttm.utils module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.utils.ForceReturn"><code class="docutils literal notranslate"><span class="pre">ForceReturn</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.utils.ForceReturn.RANDOM_INIT_LARGE"><code class="docutils literal notranslate"><span class="pre">ForceReturn.RANDOM_INIT_LARGE</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.utils.ForceReturn.RANDOM_INIT_MEDIUM"><code class="docutils literal notranslate"><span class="pre">ForceReturn.RANDOM_INIT_MEDIUM</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.utils.ForceReturn.RANDOM_INIT_SMALL"><code class="docutils literal notranslate"><span class="pre">ForceReturn.RANDOM_INIT_SMALL</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.utils.ForceReturn.ROLLING"><code class="docutils literal notranslate"><span class="pre">ForceReturn.ROLLING</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.utils.ForceReturn.ZEROPAD"><code class="docutils literal notranslate"><span class="pre">ForceReturn.ZEROPAD</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.utils.ModelSize"><code class="docutils literal notranslate"><span class="pre">ModelSize</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.utils.ModelSize.LARGE"><code class="docutils literal notranslate"><span class="pre">ModelSize.LARGE</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.utils.ModelSize.MEDIUM"><code class="docutils literal notranslate"><span class="pre">ModelSize.MEDIUM</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.utils.ModelSize.SMALL"><code class="docutils literal notranslate"><span class="pre">ModelSize.SMALL</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.utils.RMSELoss"><code class="docutils literal notranslate"><span class="pre">RMSELoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.utils.RMSELoss.forward"><code class="docutils literal notranslate"><span class="pre">RMSELoss.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.utils.check_ttm_model_path"><code class="docutils literal notranslate"><span class="pre">check_ttm_model_path()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.utils.count_parameters"><code class="docutils literal notranslate"><span class="pre">count_parameters()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.utils.get_frequency_token"><code class="docutils literal notranslate"><span class="pre">get_frequency_token()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.utils.get_model"><code class="docutils literal notranslate"><span class="pre">get_model()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.ttm.html#dsipts.models.ttm.utils.get_random_ttm"><code class="docutils literal notranslate"><span class="pre">get_random_ttm()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.ttm.html#module-dsipts.models.ttm">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dsipts.models.vva.html">dsipts.models.vva package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.vva.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.vva.html#module-dsipts.models.vva.minigpt">dsipts.models.vva.minigpt module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.minigpt.Block"><code class="docutils literal notranslate"><span class="pre">Block</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.minigpt.Block.forward"><code class="docutils literal notranslate"><span class="pre">Block.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.minigpt.CausalSelfAttention"><code class="docutils literal notranslate"><span class="pre">CausalSelfAttention</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.minigpt.CausalSelfAttention.forward"><code class="docutils literal notranslate"><span class="pre">CausalSelfAttention.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.minigpt.NewGELU"><code class="docutils literal notranslate"><span class="pre">NewGELU</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.minigpt.NewGELU.forward"><code class="docutils literal notranslate"><span class="pre">NewGELU.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.vva.html#module-dsipts.models.vva.vqvae">dsipts.models.vva.vqvae module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.vqvae.Decoder"><code class="docutils literal notranslate"><span class="pre">Decoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.vqvae.Decoder.forward"><code class="docutils literal notranslate"><span class="pre">Decoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.vqvae.Encoder"><code class="docutils literal notranslate"><span class="pre">Encoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.vqvae.Encoder.forward"><code class="docutils literal notranslate"><span class="pre">Encoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.vqvae.Jitter"><code class="docutils literal notranslate"><span class="pre">Jitter</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.vqvae.Jitter.forward"><code class="docutils literal notranslate"><span class="pre">Jitter.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.vqvae.Residual"><code class="docutils literal notranslate"><span class="pre">Residual</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.vqvae.Residual.forward"><code class="docutils literal notranslate"><span class="pre">Residual.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.vqvae.ResidualStack"><code class="docutils literal notranslate"><span class="pre">ResidualStack</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.vqvae.ResidualStack.forward"><code class="docutils literal notranslate"><span class="pre">ResidualStack.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.vqvae.VQVAE"><code class="docutils literal notranslate"><span class="pre">VQVAE</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.vqvae.VQVAE.forward"><code class="docutils literal notranslate"><span class="pre">VQVAE.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.vqvae.VectorQuantizer"><code class="docutils literal notranslate"><span class="pre">VectorQuantizer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.vqvae.VectorQuantizer.forward"><code class="docutils literal notranslate"><span class="pre">VectorQuantizer.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.vqvae.VectorQuantizerEMA"><code class="docutils literal notranslate"><span class="pre">VectorQuantizerEMA</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.vva.html#dsipts.models.vva.vqvae.VectorQuantizerEMA.forward"><code class="docutils literal notranslate"><span class="pre">VectorQuantizerEMA.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.vva.html#module-dsipts.models.vva">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dsipts.models.xlstm.html">dsipts.models.xlstm package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.xlstm.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.xlstm.html#module-dsipts.models.xlstm.xLSTM">dsipts.models.xlstm.xLSTM module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.xlstm.html#dsipts.models.xlstm.xLSTM.mLSTM"><code class="docutils literal notranslate"><span class="pre">mLSTM</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.xlstm.html#dsipts.models.xlstm.xLSTM.mLSTM.forward"><code class="docutils literal notranslate"><span class="pre">mLSTM.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.xlstm.html#dsipts.models.xlstm.xLSTM.mLSTM.init_hidden"><code class="docutils literal notranslate"><span class="pre">mLSTM.init_hidden()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.xlstm.html#dsipts.models.xlstm.xLSTM.mLSTM.reset_parameters"><code class="docutils literal notranslate"><span class="pre">mLSTM.reset_parameters()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.xlstm.html#dsipts.models.xlstm.xLSTM.sLSTM"><code class="docutils literal notranslate"><span class="pre">sLSTM</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.xlstm.html#dsipts.models.xlstm.xLSTM.sLSTM.forward"><code class="docutils literal notranslate"><span class="pre">sLSTM.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.xlstm.html#dsipts.models.xlstm.xLSTM.sLSTM.init_hidden"><code class="docutils literal notranslate"><span class="pre">sLSTM.init_hidden()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.xlstm.html#dsipts.models.xlstm.xLSTM.sLSTM.reset_parameters"><code class="docutils literal notranslate"><span class="pre">sLSTM.reset_parameters()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.xlstm.html#dsipts.models.xlstm.xLSTM.xLSTM"><code class="docutils literal notranslate"><span class="pre">xLSTM</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.xlstm.html#dsipts.models.xlstm.xLSTM.xLSTM.forward"><code class="docutils literal notranslate"><span class="pre">xLSTM.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dsipts.models.xlstm.html#dsipts.models.xlstm.xLSTM.xLSTMBlock"><code class="docutils literal notranslate"><span class="pre">xLSTMBlock</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.xlstm.html#dsipts.models.xlstm.xLSTM.xLSTMBlock.forward"><code class="docutils literal notranslate"><span class="pre">xLSTMBlock.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="dsipts.models.xlstm.html#dsipts.models.xlstm.xLSTM.xLSTMBlock.reset_parameters"><code class="docutils literal notranslate"><span class="pre">xLSTMBlock.reset_parameters()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dsipts.models.xlstm.html#module-dsipts.models.xlstm">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading">¶</a></h2>
</section>
<section id="module-dsipts.models.Autoformer">
<span id="dsipts-models-autoformer-module"></span><h2>dsipts.models.Autoformer module<a class="headerlink" href="#module-dsipts.models.Autoformer" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.Autoformer.Autoformer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.Autoformer.</span></span><span class="sig-name descname"><span class="pre">Autoformer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label_len</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'torch.nn.ReLU'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layer_encoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layer_decoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1048</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Autoformer.Autoformer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<p>Autoformer from <a class="reference external" href="https://github.com/cure-lab/LTSF-Linear">https://github.com/cure-lab/LTSF-Linear</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>label_len</strong> (<em>int</em>) – see the original implementation, seems like a warmup dimension (the decoder part will produce also some past predictions that are filter out at the end)</p></li>
<li><p><strong>d_model</strong> (<em>int</em>) – embedding dimension of the attention layer</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – dropout raye</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size</p></li>
<li><p><strong>activation</strong> (<em>str</em><em>, </em><em>optional</em>) – _description_. Defaults to ‘torch.nn.ReLU’.</p></li>
<li><p><strong>factor</strong> (<em>int</em><em>, </em><em>optional</em>) – parameter of <cite>.autoformer.layers.AutoCorrelation</cite> for find the top k. Defaults to 0.5.</p></li>
<li><p><strong>n_head</strong> (<em>int</em><em>, </em><em>optional</em>) – number of heads. Defaults to 1.</p></li>
<li><p><strong>n_layer_encoder</strong> (<em>int</em><em>, </em><em>optional</em>) – number of  encoder layers. Defaults to 2.</p></li>
<li><p><strong>n_layer_decoder</strong> (<em>int</em><em>, </em><em>optional</em>) – number of decoder layers. Defaults to 2.</p></li>
<li><p><strong>hidden_size</strong> (<em>int</em><em>, </em><em>optional</em>) – output dimension of the transformer layer. Defaults to 1048.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Autoformer.Autoformer.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Autoformer.Autoformer.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Autoformer.Autoformer.description">
<span class="sig-name descname"><span class="pre">description</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Can</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">multivariate</span> <span class="pre">output</span> <span class="pre">\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">future</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">categorical</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">Quantile</span> <span class="pre">loss</span> <span class="pre">function'</span></em><a class="headerlink" href="#dsipts.models.Autoformer.Autoformer.description" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.Autoformer.Autoformer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Autoformer.Autoformer.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forlward method used during the training loop</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – the batch structure. The keys are:
y : the target variable(s). This is always present
x_num_past: the numerical past variables. This is always present
x_num_future: the numerical future variables
x_cat_past: the categorical past variables
x_cat_future: the categorical future variables
idx_target: index of target features in the past array</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output of the mode;</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Autoformer.Autoformer.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.Autoformer.Autoformer.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Autoformer.Autoformer.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.Autoformer.Autoformer.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Autoformer.Autoformer.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.Autoformer.Autoformer.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Autoformer.Autoformer.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.Autoformer.Autoformer.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Autoformer.Autoformer.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Autoformer.Autoformer.prepare_data_per_node" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Autoformer.Autoformer.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Autoformer.Autoformer.training" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-dsipts.models.CrossFormer">
<span id="dsipts-models-crossformer-module"></span><h2>dsipts.models.CrossFormer module<a class="headerlink" href="#module-dsipts.models.CrossFormer" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.CrossFormer.CrossFormer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.CrossFormer.</span></span><span class="sig-name descname"><span class="pre">CrossFormer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">https://openreview.net/forum?id=vSVLM2j9eie</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.CrossFormer.CrossFormer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d_model</strong> (<em>int</em>) – The dimensionality of the model.</p></li>
<li><p><strong>hidden_size</strong> (<em>int</em>) – The size of the hidden layers.</p></li>
<li><p><strong>n_head</strong> (<em>int</em>) – The number of attention heads.</p></li>
<li><p><strong>seg_len</strong> (<em>int</em>) – The length of the segments.</p></li>
<li><p><strong>n_layer_encoder</strong> (<em>int</em>) – The number of layers in the encoder.</p></li>
<li><p><strong>win_size</strong> (<em>int</em>) – The size of the window for attention.</p></li>
<li><p><strong>factor</strong> (<em>int</em><em>, </em><em>optional</em>) – see .crossformer.attn.TwoStageAttentionLayer. Defaults to 10.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – The dropout rate. Defaults to 0.1.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em>, </em><em>optional</em>) – The activation function to use. Defaults to ‘torch.nn.ReLU’.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments for the parent class.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>This method does not return a value.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the activation function is not recognized.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.CrossFormer.CrossFormer.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.CrossFormer.CrossFormer.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.CrossFormer.CrossFormer.description">
<span class="sig-name descname"><span class="pre">description</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Can</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">multivariate</span> <span class="pre">output</span> <span class="pre">\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">future</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">categorical</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">Quantile</span> <span class="pre">loss</span> <span class="pre">function'</span></em><a class="headerlink" href="#dsipts.models.CrossFormer.CrossFormer.description" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.CrossFormer.CrossFormer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.CrossFormer.CrossFormer.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forlward method used during the training loop</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – the batch structure. The keys are:
y : the target variable(s). This is always present
x_num_past: the numerical past variables. This is always present
x_num_future: the numerical future variables
x_cat_past: the categorical past variables
x_cat_future: the categorical future variables
idx_target: index of target features in the past array</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output of the mode;</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.CrossFormer.CrossFormer.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.CrossFormer.CrossFormer.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.CrossFormer.CrossFormer.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.CrossFormer.CrossFormer.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.CrossFormer.CrossFormer.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.CrossFormer.CrossFormer.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.CrossFormer.CrossFormer.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.CrossFormer.CrossFormer.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.CrossFormer.CrossFormer.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.CrossFormer.CrossFormer.prepare_data_per_node" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.CrossFormer.CrossFormer.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.CrossFormer.CrossFormer.training" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-dsipts.models.D3VAE">
<span id="dsipts-models-d3vae-module"></span><h2>dsipts.models.D3VAE module<a class="headerlink" href="#module-dsipts.models.D3VAE" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.D3VAE.D3VAE">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.D3VAE.</span></span><span class="sig-name descname"><span class="pre">D3VAE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">diff_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'kl'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta_end</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta_schedule</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'linear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_preprocess_blocks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_preprocess_cells</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_channels_enc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arch_instance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'res_mbconv'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_latent_per_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_channels_dec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups_per_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_postprocess_blocks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_postprocess_cells</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'h'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.D3VAE.D3VAE" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<p>This is the basic model, each model implemented must overwrite the init method and the forward method.
The inference step is optional, by default it uses the forward method but for recurrent
network you should implement your own method</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>verbose</strong> (<em>bool</em>) – Flag to enable verbose logging.</p></li>
<li><p><strong>past_steps</strong> (<em>int</em>) – Number of past time steps to consider.</p></li>
<li><p><strong>future_steps</strong> (<em>int</em>) – Number of future time steps to predict.</p></li>
<li><p><strong>past_channels</strong> (<em>int</em>) – Number of channels in the past input data.</p></li>
<li><p><strong>future_channels</strong> (<em>int</em>) – Number of channels in the future input data.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>embs_past</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of embedding dimensions for past data.</p></li>
<li><p><strong>embs_fut</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of embedding dimensions for future data.</p></li>
<li><p><strong>n_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of classes for classification. Defaults to 0.</p></li>
<li><p><strong>persistence_weight</strong> (<em>float</em><em>, </em><em>optional</em>) – Weight for persistence in loss calculation. Defaults to 0.0.</p></li>
<li><p><strong>loss_type</strong> (<em>str</em><em>, </em><em>optional</em>) – Type of loss function to use (‘l1’ or ‘mse’). Defaults to ‘l1’.</p></li>
<li><p><strong>quantiles</strong> (<em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>) – List of quantiles for quantile loss. Defaults to an empty list.</p></li>
<li><p><strong>reduction_mode</strong> (<em>str</em><em>, </em><em>optional</em>) – Mode for reduction for categorical embedding layer (‘mean’, ‘sum’, ‘none’). Defaults to ‘mean’.</p></li>
<li><p><strong>use_classical_positional_encoder</strong> (<em>bool</em><em>, </em><em>optional</em>) – Flag to use classical positional encoding or using embedding layer also for the positions. Defaults to False.</p></li>
<li><p><strong>emb_dim</strong> (<em>int</em><em>, </em><em>optional</em>) – Dimension of categorical embeddings. Defaults to 16.</p></li>
<li><p><strong>optim</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>None</em><em>]</em><em>, </em><em>optional</em>) – Optimizer type. Defaults to None.</p></li>
<li><p><strong>optim_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – Configuration for the optimizer. Defaults to None.</p></li>
<li><p><strong>scheduler_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – Configuration for the learning rate scheduler. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>AssertionError</strong> – If the number of quantiles is not equal to 3 when quantiles are provided.</p></li>
<li><p><strong>AssertionError</strong> – If the number of output channels is not 1 for classification tasks.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.D3VAE.D3VAE.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tensor</span></span></span><a class="headerlink" href="#dsipts.models.D3VAE.D3VAE.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forlward method used during the training loop</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – the batch structure. The keys are:
y : the target variable(s). This is always present
x_num_past: the numerical past variables. This is always present
x_num_future: the numerical future variables
x_cat_past: the categorical past variables
x_cat_future: the categorical future variables
idx_target: index of target features in the past array</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output of the mode;</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.D3VAE.D3VAE.inference">
<span class="sig-name descname"><span class="pre">inference</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tensor</span></span></span><a class="headerlink" href="#dsipts.models.D3VAE.D3VAE.inference" title="Link to this definition">¶</a></dt>
<dd><p>Care here, we need to implement it because for predicting the N-step it will use the prediction at step N-1. TODO fix if because I did not implement the
know continuous variable presence here</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – batch of the dataloader</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>result</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dsipts.models.D3VAE.copy_parameters">
<span class="sig-prename descclassname"><span class="pre">dsipts.models.D3VAE.</span></span><span class="sig-name descname"><span class="pre">copy_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">net_source</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_dest</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dsipts.models.D3VAE.copy_parameters" title="Link to this definition">¶</a></dt>
<dd><p>Copies parameters from one network to another.
:param net_source: Input network.
:param net_dest: Output network.
:param strict: whether to strictly enforce that the keys</p>
<blockquote>
<div><p>in <code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code> match the keys returned by this module’s
<code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
</div></blockquote>
</dd></dl>

</section>
<section id="module-dsipts.models.Diffusion">
<span id="dsipts-models-diffusion-module"></span><h2>dsipts.models.Diffusion module<a class="headerlink" href="#module-dsipts.models.Diffusion" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.Diffusion">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.Diffusion.</span></span><span class="sig-name descname"><span class="pre">Diffusion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learn_var</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cosine_alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">diffusion_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layers_RNN</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_head</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subnet</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perc_subnet_learning_for_step</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistence_weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'l1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantiles</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optim_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Diffusion.Diffusion" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<p>Denoising Diffusion Probabilistic Model</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d_model</strong> (<em>int</em>)</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – number of target variables</p></li>
<li><p><strong>past_steps</strong> (<em>int</em>) – size of past window</p></li>
<li><p><strong>future_steps</strong> (<em>int</em>) – size of future window to be predicted</p></li>
<li><p><strong>past_channels</strong> (<em>int</em>) – number of variables available for the past context</p></li>
<li><p><strong>future_channels</strong> (<em>int</em>) – number of variables known in the future, available for forecasting</p></li>
<li><p><strong>embs</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – categorical variables dimensions for embeddings</p></li>
<li><p><strong>learn_var</strong> (<em>bool</em>) – Flag to make the model train the posterior variance (if True) or use the variance of posterior distribution</p></li>
<li><p><strong>cosine_alpha</strong> (<em>bool</em>) – Flag for the generation of alphas and betas</p></li>
<li><p><strong>diffusion_steps</strong> (<em>int</em>) – number of noising steps for the initial sample</p></li>
<li><p><strong>beta</strong> (<em>float</em>) – starting variable to generate the diffusion perturbations. Ignored if cosine_alpha == True</p></li>
<li><p><strong>gamma</strong> (<em>float</em>) – trade_off variable to balance loss over noise prediction and NegativeLikelihood/KL_Divergence.</p></li>
<li><p><strong>n_layers_RNN</strong> (<em>int</em>) – param for subnet</p></li>
<li><p><strong>d_head</strong> (<em>int</em>) – param for subnet</p></li>
<li><p><strong>n_head</strong> (<em>int</em>) – param for subnet</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – param for subnet</p></li>
<li><p><strong>activation</strong> (<em>str</em>) – param for subnet</p></li>
<li><p><strong>subnet</strong> (<em>int</em>) – =1 for attention subnet, =2 for linear subnet. Others can be added(wait for Black Friday for discounts)</p></li>
<li><p><strong>perc_subnet_learning_for_step</strong> (<em>float</em>) – percentage to choose how many subnet has to be trained for every batch. Decrease this value if the loss blows up.</p></li>
<li><p><strong>persistence_weight</strong> (<em>float</em><em>, </em><em>optional</em>) – Defaults to 0.0.</p></li>
<li><p><strong>loss_type</strong> (<em>str</em><em>, </em><em>optional</em>) – Defaults to ‘l1’.</p></li>
<li><p><strong>quantiles</strong> (<em>List</em><em>[</em><em>float</em><em>]</em><em>, </em><em>optional</em>) – Only [] accepted. Defaults to [].</p></li>
<li><p><strong>optim</strong> (<em>Union</em><em>[</em><em>str</em><em>,</em><em>None</em><em>]</em><em>, </em><em>optional</em>) – Defaults to None.</p></li>
<li><p><strong>optim_config</strong> (<em>Union</em><em>[</em><em>dict</em><em>,</em><em>None</em><em>]</em><em>, </em><em>optional</em>) – Defaults to None.</p></li>
<li><p><strong>scheduler_config</strong> (<em>Union</em><em>[</em><em>dict</em><em>,</em><em>None</em><em>]</em><em>, </em><em>optional</em>) – Defaults to None.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.Diffusion.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Diffusion.Diffusion.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.Diffusion.cat_categorical_vars">
<span class="sig-name descname"><span class="pre">cat_categorical_vars</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Diffusion.Diffusion.cat_categorical_vars" title="Link to this definition">¶</a></dt>
<dd><p>Extracting categorical context about past and future</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – Keys checked -&gt; [‘x_cat_past’, ‘x_cat_future’]</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>cat_emb_past, cat_emb_fut</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.Diffusion.description">
<span class="sig-name descname"><span class="pre">description</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Can</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">multivariate</span> <span class="pre">output</span> <span class="pre">\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">future</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">categorical</span> <span class="pre">covariates\nCan</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">Quantile</span> <span class="pre">loss</span> <span class="pre">function'</span></em><a class="headerlink" href="#dsipts.models.Diffusion.Diffusion.description" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.Diffusion.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#dsipts.models.Diffusion.Diffusion.forward" title="Link to this definition">¶</a></dt>
<dd><p>training process of the diffusion network</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – variables loaded</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>total loss about the prediction of the noises over all subnets extracted</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.Diffusion.gaussian_likelihood">
<span class="sig-name descname"><span class="pre">gaussian_likelihood</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">var</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Diffusion.Diffusion.gaussian_likelihood" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.Diffusion.gaussian_log_likelihood">
<span class="sig-name descname"><span class="pre">gaussian_log_likelihood</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">var</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Diffusion.Diffusion.gaussian_log_likelihood" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.Diffusion.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.Diffusion.Diffusion.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.Diffusion.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.Diffusion.Diffusion.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.Diffusion.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.Diffusion.Diffusion.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.Diffusion.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.Diffusion.Diffusion.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.Diffusion.improving_weight_during_training">
<span class="sig-name descname"><span class="pre">improving_weight_during_training</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Diffusion.Diffusion.improving_weight_during_training" title="Link to this definition">¶</a></dt>
<dd><p>Each time we sample from multinomial we subtract the minimum for more precise sampling,
avoiding great learning differences among subnets</p>
<p>This lead to more stable inference also in early training, mainly for common context embedding.</p>
<p>For probabilistic reason, weights has to be &gt;0, so we subtract min-1</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.Diffusion.inference">
<span class="sig-name descname"><span class="pre">inference</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dsipts.models.Diffusion.Diffusion.inference" title="Link to this definition">¶</a></dt>
<dd><p>Inference process to forecast future y</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – Keys checked [‘x_num_past, ‘idx_target’, ‘x_num_future’, ‘x_cat_past’, ‘x_cat_future’]</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>generated sequence [batch_size, future_steps, num_var]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.Diffusion.normal_kl">
<span class="sig-name descname"><span class="pre">normal_kl</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logvar1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logvar2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Diffusion.Diffusion.normal_kl" title="Link to this definition">¶</a></dt>
<dd><p>Compute the KL divergence between two gaussians. Also called relative entropy.
KL divergence of P from Q is the expected excess surprise from using Q as a model when the actual distribution is P.
KL(P||Q) = P*log(P/Q) or -P*log(Q/P)</p>
<p># In the context of machine learning, KL(P||Q) is often called the ‘information gain’
# achieved if P would be used instead of Q which is currently used.</p>
<p>Shapes are automatically broadcasted, so batches can be compared to
scalars, among other use cases.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.Diffusion.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Diffusion.Diffusion.prepare_data_per_node" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.Diffusion.q_sample">
<span class="sig-name descname"><span class="pre">q_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_start</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dsipts.models.Diffusion.Diffusion.q_sample" title="Link to this definition">¶</a></dt>
<dd><p>Diffuse x_start for t diffusion steps.</p>
<p>In other words, sample from q(x_t | x_0).</p>
<p>Also, compute the mean and variance of the diffusion posterior:</p>
<blockquote>
<div><p>q(x_{t-1} | x_t, x_0)</p>
</div></blockquote>
<p>Posterior mean and variance are the ones to be predicted</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_start</strong> (<em>torch.Tensor</em>) – values to be predicted</p></li>
<li><p><strong>t</strong> (<em>int</em>) – diffusion step</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>q_sample, posterior mean, posterior log variance and the actual noise</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[torch.Tensor, torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.Diffusion.remove_var">
<span class="sig-name descname"><span class="pre">remove_var</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indexes_to_exclude</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dsipts.models.Diffusion.Diffusion.remove_var" title="Link to this definition">¶</a></dt>
<dd><p>Function to remove variables from tensors in chosen dimension and position</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> (<em>torch.Tensor</em>) – starting tensor</p></li>
<li><p><strong>indexes_to_exclude</strong> (<em>list</em>) – index of the chosen dimension we want t oexclude</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – dimension of the tensor on which we want to work (not list od dims!!)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>new tensor without the chosen variables</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.Diffusion.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Diffusion.Diffusion.training" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.SubNet1">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.Diffusion.</span></span><span class="sig-name descname"><span class="pre">SubNet1</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">aux_past_ch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aux_fut_ch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learn_var</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_channel</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_head</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Diffusion.SubNet1" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>-&gt; SUBNET of the DIFFUSION MODEL (DDPM)</p>
<p>It starts with an autoregressive LSTM Network computation of epsilon, then subtracted to ‘y_noised’ tensor. This is always possible!
Now we have an approximation of our ‘eps_hat’, that at the end will pass in a residual connection with its embedded version ‘emb_eps_hat’.</p>
<p>‘emb_eps_hat’ will be update with respect to available info about categorical values of our serie:
Through an ATTENTION Network we compare past categorical with future categorical to update the embedded noise predicted.</p>
<p>Also, if we have values about auxiliary numerical variables both in past and future, the changes of these variables will be fetched
by another ATTENTION Network.</p>
<p>The goal is ensure valuable computations for ‘eps’ always, and then updating things if we have enough data.
Both attentions uses { Q = <a href="#id1"><span class="problematic" id="id2">*</span></a>_future, K = <a href="#id3"><span class="problematic" id="id4">*</span></a>_past, V = y_past } using as much as possible context variables for better updates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>learn_var</strong> (<em>bool</em>) – set if the network has to learn the optim variance of each step</p></li>
<li><p><strong>output_channel</strong> (<em>int</em>) – number of variables to be predicted</p></li>
<li><p><strong>future_steps</strong> (<em>int</em>) – number of step in the future, so the number of timesstep to be predicted</p></li>
<li><p><strong>d_model</strong> (<em>int</em>) – hidden dimension of the model</p></li>
<li><p><strong>num_layers_RNN</strong> (<em>int</em>) – number of layers for autoregressive prediction</p></li>
<li><p><strong>d_head</strong> (<em>int</em>) – number of heads for Attention Networks</p></li>
<li><p><strong>n_head</strong> (<em>int</em>) – hidden dimension of heads for Attention Networks</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.SubNet1.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_noised</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_past</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cat_past</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cat_fut</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_past</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fut</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Diffusion.SubNet1.forward" title="Link to this definition">¶</a></dt>
<dd><p>‘DIFFUSION SUBNET
:param y_noised: [B, future_step, num_var]
:type y_noised: torch.Tensor
:param y_past: [B, past_step, num_var]
:type y_past: torch.Tensor
:param cat_past: [B, past_step, d_model]. Defaults to None.
:type cat_past: torch.Tensor, optional
:param cat_fut: [B, future_step, d_model]. Defaults to None.
:type cat_fut: torch.Tensor, optional
:param num_past: [B, past_step, d_model]. Defaults to None.
:type num_past: torch.Tensor, optional
:param num_fut: [B, future_step, d_model]. Defaults to None.
:type num_fut: torch.Tensor, optional</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>predicted noise [B, future_step, num_var]. According to ‘learn_var’ param in initialization, the subnet returns another tensor of same size about the variance</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.SubNet2">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.Diffusion.</span></span><span class="sig-name descname"><span class="pre">SubNet2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">aux_past_ch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aux_fut_ch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learn_var</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_channel</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Diffusion.SubNet2" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.SubNet2.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_noised</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_past</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cat_past</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cat_fut</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_past</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fut</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Diffusion.SubNet2.forward" title="Link to this definition">¶</a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.SubNet3">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.Diffusion.</span></span><span class="sig-name descname"><span class="pre">SubNet3</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">learn_var</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flag_aux_num</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_var</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_step</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_head</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Diffusion.SubNet3" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.Diffusion.SubNet3.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_noised</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_past</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cat_past</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cat_fut</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_past</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fut</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Diffusion.SubNet3.forward" title="Link to this definition">¶</a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="module-dsipts.models.DilatedConv">
<span id="dsipts-models-dilatedconv-module"></span><h2>dsipts.models.DilatedConv module<a class="headerlink" href="#module-dsipts.models.DilatedConv" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.DilatedConv.Block">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.DilatedConv.</span></span><span class="sig-name descname"><span class="pre">Block</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sum_layers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.DilatedConv.Block" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.DilatedConv.Block.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tensor</span></span></span><a class="headerlink" href="#dsipts.models.DilatedConv.Block.forward" title="Link to this definition">¶</a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.DilatedConv.DilatedConv">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.DilatedConv.</span></span><span class="sig-name descname"><span class="pre">DilatedConv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sum_layers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_RNN</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers_RNN</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kind</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'torch.nn.ReLU'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_last</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_glu</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">glu_percentage</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.DilatedConv.DilatedConv" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<p>Custom encoder-decoder</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sum_layers</strong> (<em>bool</em>) – Flag indicating whether to sum the layers.</p></li>
<li><p><strong>hidden_RNN</strong> (<em>int</em>) – Number of hidden units in the RNN.</p></li>
<li><p><strong>num_layers_RNN</strong> (<em>int</em>) – Number of layers in the RNN.</p></li>
<li><p><strong>kind</strong> (<em>str</em>) – Type of RNN to use (e.g., ‘LSTM’, ‘GRU’).</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Size of the convolutional kernel.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em>, </em><em>optional</em>) – Activation function to use. Defaults to ‘torch.nn.ReLU’.</p></li>
<li><p><strong>remove_last</strong> (<em>bool</em><em>, </em><em>optional</em>) – Flag to indicate whether to remove the last element in the sequence. Defaults to False.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – Dropout rate for regularization. Defaults to 0.1.</p></li>
<li><p><strong>use_bn</strong> (<em>bool</em><em>, </em><em>optional</em>) – Flag to indicate whether to use batch normalization. Defaults to False.</p></li>
<li><p><strong>use_glu</strong> (<em>bool</em><em>, </em><em>optional</em>) – Flag to indicate whether to use Gated Linear Units (GLU). Defaults to True.</p></li>
<li><p><strong>glu_percentage</strong> (<em>float</em><em>, </em><em>optional</em>) – Percentage of GLU to apply. Defaults to 1.0.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.DilatedConv.DilatedConv.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.DilatedConv.DilatedConv.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.DilatedConv.DilatedConv.description">
<span class="sig-name descname"><span class="pre">description</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Can</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">multivariate</span> <span class="pre">output</span> <span class="pre">\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">future</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">categorical</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">Quantile</span> <span class="pre">loss</span> <span class="pre">function'</span></em><a class="headerlink" href="#dsipts.models.DilatedConv.DilatedConv.description" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.DilatedConv.DilatedConv.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.DilatedConv.DilatedConv.forward" title="Link to this definition">¶</a></dt>
<dd><p>It is mandatory to implement this method</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – batch of the dataloader</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>result</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.DilatedConv.DilatedConv.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.DilatedConv.DilatedConv.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.DilatedConv.DilatedConv.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.DilatedConv.DilatedConv.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.DilatedConv.DilatedConv.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.DilatedConv.DilatedConv.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.DilatedConv.DilatedConv.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.DilatedConv.DilatedConv.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.DilatedConv.DilatedConv.inference">
<span class="sig-name descname"><span class="pre">inference</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tensor</span></span></span><a class="headerlink" href="#dsipts.models.DilatedConv.DilatedConv.inference" title="Link to this definition">¶</a></dt>
<dd><p>Usually it is ok to return the output of the forward method but sometimes not (e.g. RNN)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – batch</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>result</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.DilatedConv.DilatedConv.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.DilatedConv.DilatedConv.prepare_data_per_node" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.DilatedConv.DilatedConv.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.DilatedConv.DilatedConv.training" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.DilatedConv.GLU">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.DilatedConv.</span></span><span class="sig-name descname"><span class="pre">GLU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.DilatedConv.GLU" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Gated Linear Unit, ‘Gate’ block in TFT paper
Sub net of GRN: linear(x) * sigmoid(linear(x))
No dimension changes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>d_model</strong> (<em>int</em>) – model dimension</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.DilatedConv.GLU.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dsipts.models.DilatedConv.GLU.forward" title="Link to this definition">¶</a></dt>
<dd><p>Gated Linear Unit
Sub net of GRN: linear(x) * sigmoid(linear(x))
No dimension changes: [bs, seq_len, d_model]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-dsipts.models.DilatedConvED">
<span id="dsipts-models-dilatedconved-module"></span><h2>dsipts.models.DilatedConvED module<a class="headerlink" href="#module-dsipts.models.DilatedConvED" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.DilatedConvED.Block">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.DilatedConvED.</span></span><span class="sig-name descname"><span class="pre">Block</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sum_layers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.DilatedConvED.Block" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.DilatedConvED.Block.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tensor</span></span></span><a class="headerlink" href="#dsipts.models.DilatedConvED.Block.forward" title="Link to this definition">¶</a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.DilatedConvED.DilatedConvED">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.DilatedConvED.</span></span><span class="sig-name descname"><span class="pre">DilatedConvED</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sum_layers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_RNN</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers_RNN</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kind</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_cumsum</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bilinear</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'torch.nn.ReLU'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.DilatedConvED.DilatedConvED" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<p>Initialize the model with specified parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sum_layers</strong> (<em>bool</em>) – Flag indicating whether to sum layers in the encoder/decoder blocks.</p></li>
<li><p><strong>hidden_RNN</strong> (<em>int</em>) – Number of hidden units in the RNN.</p></li>
<li><p><strong>num_layers_RNN</strong> (<em>int</em>) – Number of layers in the RNN.</p></li>
<li><p><strong>kind</strong> (<em>str</em>) – Type of RNN to use (‘lstm’ or ‘gru’).</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Size of the convolutional kernel.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – Dropout rate for regularization. Defaults to 0.1.</p></li>
<li><p><strong>use_bn</strong> (<em>bool</em><em>, </em><em>optional</em>) – Flag to use batch normalization. Defaults to False.</p></li>
<li><p><strong>use_cumsum</strong> (<em>bool</em><em>, </em><em>optional</em>) – Flag to use cumulative sum. Defaults to True.</p></li>
<li><p><strong>use_bilinear</strong> (<em>bool</em><em>, </em><em>optional</em>) – Flag to use bilinear layers. Defaults to False.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em>, </em><em>optional</em>) – Activation function to use. Defaults to ‘torch.nn.ReLU’.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the specified activation function is not recognized or if the kind is not ‘lstm’ or ‘gru’.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.DilatedConvED.DilatedConvED.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.DilatedConvED.DilatedConvED.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.DilatedConvED.DilatedConvED.description">
<span class="sig-name descname"><span class="pre">description</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Can</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">multivariate</span> <span class="pre">output</span> <span class="pre">\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">future</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">categorical</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">Quantile</span> <span class="pre">loss</span> <span class="pre">function'</span></em><a class="headerlink" href="#dsipts.models.DilatedConvED.DilatedConvED.description" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.DilatedConvED.DilatedConvED.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.DilatedConvED.DilatedConvED.forward" title="Link to this definition">¶</a></dt>
<dd><p>It is mandatory to implement this method</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – batch of the dataloader</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>result</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.DilatedConvED.DilatedConvED.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.DilatedConvED.DilatedConvED.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.DilatedConvED.DilatedConvED.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.DilatedConvED.DilatedConvED.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.DilatedConvED.DilatedConvED.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.DilatedConvED.DilatedConvED.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.DilatedConvED.DilatedConvED.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.DilatedConvED.DilatedConvED.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.DilatedConvED.DilatedConvED.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.DilatedConvED.DilatedConvED.prepare_data_per_node" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.DilatedConvED.DilatedConvED.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.DilatedConvED.DilatedConvED.training" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.DilatedConvED.GLU">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.DilatedConvED.</span></span><span class="sig-name descname"><span class="pre">GLU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.DilatedConvED.GLU" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Gated Linear Unit, ‘Gate’ block in TFT paper
Sub net of GRN: linear(x) * sigmoid(linear(x))
No dimension changes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>d_model</strong> (<em>int</em>) – model dimension</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.DilatedConvED.GLU.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dsipts.models.DilatedConvED.GLU.forward" title="Link to this definition">¶</a></dt>
<dd><p>Gated Linear Unit
Sub net of GRN: linear(x) * sigmoid(linear(x))
No dimension changes: [bs, seq_len, d_model]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-dsipts.models.Duet">
<span id="dsipts-models-duet-module"></span><h2>dsipts.models.Duet module<a class="headerlink" href="#module-dsipts.models.Duet" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.Duet.Duet">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.Duet.</span></span><span class="sig-name descname"><span class="pre">Duet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">CI</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_ff</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noisy_gating</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_experts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Duet.Duet" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<p>Initializes the model with the specified parameters. <a class="reference external" href="https://github.com/decisionintelligence/DUET">https://github.com/decisionintelligence/DUET</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>factor</strong> (<em>int</em>) – The factor for attention scaling. NOT USED but in the original implementation</p></li>
<li><p><strong>d_model</strong> (<em>int</em>) – The dimensionality of the model.</p></li>
<li><p><strong>n_head</strong> (<em>int</em>) – The number of attention heads.</p></li>
<li><p><strong>n_layer</strong> (<em>int</em>) – The number of layers in the encoder.</p></li>
<li><p><strong>CI</strong> (<em>bool</em>) – Perform channel independent operations.</p></li>
<li><p><strong>d_ff</strong> (<em>int</em>) – The dimensionality of the feedforward layer.</p></li>
<li><p><strong>noisy_gating</strong> (<em>bool</em>) – Flag to indicate if noisy gating is used.</p></li>
<li><p><strong>num_experts</strong> (<em>int</em>) – The number of experts in the mixture of experts.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – The size of the convolutional kernel.</p></li>
<li><p><strong>hidden_size</strong> (<em>int</em>) – The size of the hidden layer.</p></li>
<li><p><strong>k</strong> (<em>int</em>) – The number of clusters for the linear extractor.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – The dropout rate. Defaults to 0.1.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em>, </em><em>optional</em>) – The activation function to use. Defaults to ‘’.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the activation function is not recognized.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Duet.Duet.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Duet.Duet.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Duet.Duet.description">
<span class="sig-name descname"><span class="pre">description</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Can</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">multivariate</span> <span class="pre">output</span> <span class="pre">\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">future</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">categorical</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">Quantile</span> <span class="pre">loss</span> <span class="pre">function'</span></em><a class="headerlink" href="#dsipts.models.Duet.Duet.description" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.Duet.Duet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#dsipts.models.Duet.Duet.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forlward method used during the training loop</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – the batch structure. The keys are:
y : the target variable(s). This is always present
x_num_past: the numerical past variables. This is always present
x_num_future: the numerical future variables
x_cat_past: the categorical past variables
x_cat_future: the categorical future variables
idx_target: index of target features in the past array</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output of the mode;</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Duet.Duet.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.Duet.Duet.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Duet.Duet.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.Duet.Duet.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Duet.Duet.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.Duet.Duet.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Duet.Duet.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.Duet.Duet.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Duet.Duet.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Duet.Duet.prepare_data_per_node" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Duet.Duet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Duet.Duet.training" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-dsipts.models.ITransformer">
<span id="dsipts-models-itransformer-module"></span><h2>dsipts.models.ITransformer module<a class="headerlink" href="#module-dsipts.models.ITransformer" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.ITransformer.ITransformer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.ITransformer.</span></span><span class="sig-name descname"><span class="pre">ITransformer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layer_decoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_norm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_strategy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'projection'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.ITransformer.ITransformer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<p>Initialize the ITransformer model for time series forecasting.</p>
<p>This class implements the Inverted Transformer architecture as described in the paper
“ITRANSFORMER: INVERTED TRANSFORMERS ARE EFFECTIVE FOR TIME SERIES FORECASTING”
(<a class="reference external" href="https://arxiv.org/pdf/2310.06625">https://arxiv.org/pdf/2310.06625</a>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<em>int</em>) – The first embedding size of the model (‘r’ in the paper).</p></li>
<li><p><strong>d_model</strong> (<em>int</em>) – The second embedding size (r^{tilda} in the model). Should be smaller than hidden_size.</p></li>
<li><p><strong>n_head</strong> (<em>int</em>) – The number of attention heads.</p></li>
<li><p><strong>n_layer_decoder</strong> (<em>int</em>) – The number of layers in the decoder.</p></li>
<li><p><strong>use_norm</strong> (<em>bool</em>) – Flag to indicate whether to use normalization.</p></li>
<li><p><strong>class_strategy</strong> (<em>str</em><em>, </em><em>optional</em>) – The strategy for classification, can be ‘projection’, ‘average’, or ‘cls_token’. Defaults to ‘projection’.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – The dropout rate for regularization. Defaults to 0.1.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em>, </em><em>optional</em>) – The activation function to be used. Defaults to ‘’.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the activation function is not recognized.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.ITransformer.ITransformer.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.ITransformer.ITransformer.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.ITransformer.ITransformer.description">
<span class="sig-name descname"><span class="pre">description</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Can</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">multivariate</span> <span class="pre">output</span> <span class="pre">\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">future</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">categorical</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">Quantile</span> <span class="pre">loss</span> <span class="pre">function'</span></em><a class="headerlink" href="#dsipts.models.ITransformer.ITransformer.description" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.ITransformer.ITransformer.forecast">
<span class="sig-name descname"><span class="pre">forecast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_enc</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_mark_enc</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_dec</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_mark_dec</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.ITransformer.ITransformer.forecast" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.ITransformer.ITransformer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#dsipts.models.ITransformer.ITransformer.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forlward method used during the training loop</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – the batch structure. The keys are:
y : the target variable(s). This is always present
x_num_past: the numerical past variables. This is always present
x_num_future: the numerical future variables
x_cat_past: the categorical past variables
x_cat_future: the categorical future variables
idx_target: index of target features in the past array</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output of the mode;</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.ITransformer.ITransformer.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.ITransformer.ITransformer.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.ITransformer.ITransformer.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.ITransformer.ITransformer.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.ITransformer.ITransformer.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.ITransformer.ITransformer.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.ITransformer.ITransformer.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.ITransformer.ITransformer.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.ITransformer.ITransformer.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.ITransformer.ITransformer.prepare_data_per_node" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.ITransformer.ITransformer.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.ITransformer.ITransformer.training" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-dsipts.models.Informer">
<span id="dsipts-models-informer-module"></span><h2>dsipts.models.Informer module<a class="headerlink" href="#module-dsipts.models.Informer" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.Informer.Informer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.Informer.</span></span><span class="sig-name descname"><span class="pre">Informer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layer_encoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layer_decoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'torch.nn.ReLU'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_last</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'prob'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distil</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Informer.Informer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<p>Initialize the model with specified parameters. hhttps://github.com/zhouhaoyi/Informer2020/tree/main/models</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d_model</strong> (<em>int</em>) – The dimensionality of the model.</p></li>
<li><p><strong>hidden_size</strong> (<em>int</em>) – The size of the hidden layers.</p></li>
<li><p><strong>n_layer_encoder</strong> (<em>int</em>) – The number of layers in the encoder.</p></li>
<li><p><strong>n_layer_decoder</strong> (<em>int</em>) – The number of layers in the decoder.</p></li>
<li><p><strong>mix</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to use mixed attention. Defaults to True.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em>, </em><em>optional</em>) – The activation function to use. Defaults to ‘torch.nn.ReLU’.</p></li>
<li><p><strong>remove_last</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to remove the last layer. Defaults to False.</p></li>
<li><p><strong>attn</strong> (<em>str</em><em>, </em><em>optional</em>) – The type of attention mechanism to use. Defaults to ‘prob’.</p></li>
<li><p><strong>distil</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to use distillation. Defaults to True.</p></li>
<li><p><strong>factor</strong> (<em>int</em><em>, </em><em>optional</em>) – The factor for attention. Defaults to 5.</p></li>
<li><p><strong>n_head</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of attention heads. Defaults to 1.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – The dropout rate. Defaults to 0.1.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If any of the parameters are invalid.</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Ensure to set up split_params: shift: ${model_configs.future_steps} as it is required!!</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Informer.Informer.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Informer.Informer.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Informer.Informer.description">
<span class="sig-name descname"><span class="pre">description</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Can</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">multivariate</span> <span class="pre">output</span> <span class="pre">\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">future</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">categorical</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">Quantile</span> <span class="pre">loss</span> <span class="pre">function'</span></em><a class="headerlink" href="#dsipts.models.Informer.Informer.description" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.Informer.Informer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Informer.Informer.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forlward method used during the training loop</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – the batch structure. The keys are:
y : the target variable(s). This is always present
x_num_past: the numerical past variables. This is always present
x_num_future: the numerical future variables
x_cat_past: the categorical past variables
x_cat_future: the categorical future variables
idx_target: index of target features in the past array</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output of the mode;</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Informer.Informer.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.Informer.Informer.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Informer.Informer.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.Informer.Informer.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Informer.Informer.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.Informer.Informer.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Informer.Informer.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.Informer.Informer.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Informer.Informer.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Informer.Informer.prepare_data_per_node" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Informer.Informer.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Informer.Informer.training" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-dsipts.models.LinearTS">
<span id="dsipts-models-linearts-module"></span><h2>dsipts.models.LinearTS module<a class="headerlink" href="#module-dsipts.models.LinearTS" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.LinearTS.LinearTS">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.LinearTS.</span></span><span class="sig-name descname"><span class="pre">LinearTS</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'torch.nn.ReLU'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kind</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'linear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">simple</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.LinearTS.LinearTS" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<p>Initialize the model with specified parameters. Linear model from <a class="reference external" href="https://github.com/cure-lab/LTSF-Linear/blob/main/run_longExp.py">https://github.com/cure-lab/LTSF-Linear/blob/main/run_longExp.py</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel dimension for the initial moving average.</p></li>
<li><p><strong>hidden_size</strong> (<em>int</em>) – Hidden size of the linear block.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – Dropout rate in Dropout layers. Default is 0.1.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em>, </em><em>optional</em>) – Activation function in PyTorch. Default is ‘torch.nn.ReLU’.</p></li>
<li><p><strong>kind</strong> (<em>str</em><em>, </em><em>optional</em>) – Type of model, can be ‘linear’, ‘dlinear’ (de-trending), or ‘nlinear’ (differential). Defaults to ‘linear’.</p></li>
<li><p><strong>use_bn</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, Batch Normalization layers will be added and Dropouts will be removed. Default is False.</p></li>
<li><p><strong>simple</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, the model used is the same as illustrated in the paper; otherwise, a more complex model with the same idea is used. Default is False.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments for the parent class.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If an invalid activation function is provided.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.LinearTS.LinearTS.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.LinearTS.LinearTS.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.LinearTS.LinearTS.description">
<span class="sig-name descname"><span class="pre">description</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Can</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">multivariate</span> <span class="pre">output</span> <span class="pre">\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">future</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">categorical</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">Quantile</span> <span class="pre">loss</span> <span class="pre">function\n</span> <span class="pre">THE</span> <span class="pre">SIMPLE</span> <span class="pre">IMPLEMENTATION</span> <span class="pre">DOES</span> <span class="pre">NOT</span> <span class="pre">USE</span> <span class="pre">CATEGORICAL</span> <span class="pre">NOR</span> <span class="pre">FUTURE</span> <span class="pre">VARIABLES'</span></em><a class="headerlink" href="#dsipts.models.LinearTS.LinearTS.description" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.LinearTS.LinearTS.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.LinearTS.LinearTS.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forlward method used during the training loop</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – the batch structure. The keys are:
y : the target variable(s). This is always present
x_num_past: the numerical past variables. This is always present
x_num_future: the numerical future variables
x_cat_past: the categorical past variables
x_cat_future: the categorical future variables
idx_target: index of target features in the past array</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output of the mode;</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.LinearTS.LinearTS.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.LinearTS.LinearTS.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.LinearTS.LinearTS.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.LinearTS.LinearTS.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.LinearTS.LinearTS.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.LinearTS.LinearTS.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.LinearTS.LinearTS.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.LinearTS.LinearTS.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.LinearTS.LinearTS.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.LinearTS.LinearTS.prepare_data_per_node" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.LinearTS.LinearTS.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.LinearTS.LinearTS.training" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.LinearTS.moving_avg">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.LinearTS.</span></span><span class="sig-name descname"><span class="pre">moving_avg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.LinearTS.moving_avg" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.LinearTS.moving_avg.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.LinearTS.moving_avg.forward" title="Link to this definition">¶</a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.LinearTS.series_decomp">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.LinearTS.</span></span><span class="sig-name descname"><span class="pre">series_decomp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.LinearTS.series_decomp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.LinearTS.series_decomp.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.LinearTS.series_decomp.forward" title="Link to this definition">¶</a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="module-dsipts.models.PatchTST">
<span id="dsipts-models-patchtst-module"></span><h2>dsipts.models.PatchTST module<a class="headerlink" href="#module-dsipts.models.PatchTST" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.PatchTST.PatchTST">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.PatchTST.</span></span><span class="sig-name descname"><span class="pre">PatchTST</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patch_len</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decomposition</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'torch.nn.ReLU'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_last</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1048</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.PatchTST.PatchTST" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<p>Initializes the model with specified parameters.https://github.com/yuqinie98/PatchTST/blob/main/</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d_model</strong> (<em>int</em>) – The dimensionality of the model.</p></li>
<li><p><strong>patch_len</strong> (<em>int</em>) – The length of the patches.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – The size of the kernel for convolutional layers.</p></li>
<li><p><strong>decomposition</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to use decomposition. Defaults to True.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em>, </em><em>optional</em>) – The activation function to use. Defaults to ‘torch.nn.ReLU’.</p></li>
<li><p><strong>n_head</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of attention heads. Defaults to 1.</p></li>
<li><p><strong>n_layer</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of layers in the model. Defaults to 2.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em>, </em><em>optional</em>) – The stride for convolutional layers. Defaults to 8.</p></li>
<li><p><strong>remove_last</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to remove the last layer. Defaults to False.</p></li>
<li><p><strong>hidden_size</strong> (<em>int</em><em>, </em><em>optional</em>) – The size of the hidden layers. Defaults to 1048.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – The dropout rate for regularization. Defaults to 0.1.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the activation function is not recognized.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.PatchTST.PatchTST.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.PatchTST.PatchTST.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.PatchTST.PatchTST.description">
<span class="sig-name descname"><span class="pre">description</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Can</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">multivariate</span> <span class="pre">output</span> <span class="pre">\nCan</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">future</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">categorical</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">Quantile</span> <span class="pre">loss</span> <span class="pre">function'</span></em><a class="headerlink" href="#dsipts.models.PatchTST.PatchTST.description" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.PatchTST.PatchTST.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.PatchTST.PatchTST.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forlward method used during the training loop</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – the batch structure. The keys are:
y : the target variable(s). This is always present
x_num_past: the numerical past variables. This is always present
x_num_future: the numerical future variables
x_cat_past: the categorical past variables
x_cat_future: the categorical future variables
idx_target: index of target features in the past array</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output of the mode;</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.PatchTST.PatchTST.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.PatchTST.PatchTST.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.PatchTST.PatchTST.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.PatchTST.PatchTST.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.PatchTST.PatchTST.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.PatchTST.PatchTST.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.PatchTST.PatchTST.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.PatchTST.PatchTST.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.PatchTST.PatchTST.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.PatchTST.PatchTST.prepare_data_per_node" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.PatchTST.PatchTST.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.PatchTST.PatchTST.training" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-dsipts.models.Persistent">
<span id="dsipts-models-persistent-module"></span><h2>dsipts.models.Persistent module<a class="headerlink" href="#module-dsipts.models.Persistent" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.Persistent.Persistent">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.Persistent.</span></span><span class="sig-name descname"><span class="pre">Persistent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Persistent.Persistent" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<p>Simple persistent model aligned with all the other</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Persistent.Persistent.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Persistent.Persistent.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Persistent.Persistent.description">
<span class="sig-name descname"><span class="pre">description</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Can</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">multivariate</span> <span class="pre">output</span> <span class="pre">\nCan</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">future</span> <span class="pre">covariates\nCan</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">categorical</span> <span class="pre">covariates\nCan</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">Quantile</span> <span class="pre">loss</span> <span class="pre">function'</span></em><a class="headerlink" href="#dsipts.models.Persistent.Persistent.description" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.Persistent.Persistent.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Persistent.Persistent.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forlward method used during the training loop</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – the batch structure. The keys are:
y : the target variable(s). This is always present
x_num_past: the numerical past variables. This is always present
x_num_future: the numerical future variables
x_cat_past: the categorical past variables
x_cat_future: the categorical future variables
idx_target: index of target features in the past array</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output of the mode;</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Persistent.Persistent.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.Persistent.Persistent.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Persistent.Persistent.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.Persistent.Persistent.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Persistent.Persistent.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.Persistent.Persistent.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Persistent.Persistent.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.Persistent.Persistent.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Persistent.Persistent.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Persistent.Persistent.prepare_data_per_node" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Persistent.Persistent.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Persistent.Persistent.training" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-dsipts.models.RNN">
<span id="dsipts-models-rnn-module"></span><h2>dsipts.models.RNN module<a class="headerlink" href="#module-dsipts.models.RNN" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.RNN.MyBN">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.RNN.</span></span><span class="sig-name descname"><span class="pre">MyBN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">channels</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.RNN.MyBN" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.RNN.MyBN.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.RNN.MyBN.forward" title="Link to this definition">¶</a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.RNN.RNN">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.RNN.</span></span><span class="sig-name descname"><span class="pre">RNN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_RNN</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers_RNN</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kind</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'torch.nn.ReLU'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_last</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_blocks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bidirectional</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lstm_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'slstm'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.RNN.RNN" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<p>Initialize a recurrent model with an encoder-decoder structure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_RNN</strong> (<em>int</em>) – Hidden size of the RNN block.</p></li>
<li><p><strong>num_layers_RNN</strong> (<em>int</em>) – Number of RNN layers.</p></li>
<li><p><strong>kind</strong> (<em>str</em>) – Type of RNN to use, either ‘gru’ or ‘lstm’ or <cite>xlstm</cite>.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size in the encoder convolutional block.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em>, </em><em>optional</em>) – Activation function from PyTorch. Default is ‘torch.nn.ReLU’.</p></li>
<li><p><strong>remove_last</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, the model learns the difference with respect to the last seen point. Default is False.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – Dropout rate in Dropout layers. Default is 0.1.</p></li>
<li><p><strong>use_bn</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, Batch Normalization layers will be added and Dropouts will be removed. Default is False.</p></li>
<li><p><strong>num_blocks</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of xLSTM blocks (only for xLSTM). Default is 4.</p></li>
<li><p><strong>bidirectional</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, the RNN is bidirectional. Default is True.</p></li>
<li><p><strong>lstm_type</strong> (<em>str</em><em>, </em><em>optional</em>) – Type of LSTM to use (only for xLSTM), either ‘slstm’ or ‘mlstm’. Default is ‘slstm’.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the specified kind is not ‘lstm’, ‘gru’, or ‘xlstm’.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.RNN.RNN.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.RNN.RNN.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.RNN.RNN.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.RNN.RNN.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forlward method used during the training loop</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – the batch structure. The keys are:
y : the target variable(s). This is always present
x_num_past: the numerical past variables. This is always present
x_num_future: the numerical future variables
x_cat_past: the categorical past variables
x_cat_future: the categorical future variables
idx_target: index of target features in the past array</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output of the mode;</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.RNN.RNN.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.RNN.RNN.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.RNN.RNN.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.RNN.RNN.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.RNN.RNN.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.RNN.RNN.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.RNN.RNN.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.RNN.RNN.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.RNN.RNN.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.RNN.RNN.prepare_data_per_node" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.RNN.RNN.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.RNN.RNN.training" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-dsipts.models.Samformer">
<span id="dsipts-models-samformer-module"></span><h2>dsipts.models.Samformer module<a class="headerlink" href="#module-dsipts.models.Samformer" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.Samformer.Samformer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.Samformer.</span></span><span class="sig-name descname"><span class="pre">Samformer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_revin</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Samformer.Samformer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<p>Initialize the model with specified parameters. Samformer: Unlocking the Potential of Transformers in Time Series Forecasting with Sharpness-Aware Minimization and Channel-Wise Attention.
<a class="reference external" href="https://arxiv.org/pdf/2402.10198">https://arxiv.org/pdf/2402.10198</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<em>int</em>) – The size of the hidden layer.</p></li>
<li><p><strong>use_revin</strong> (<em>bool</em>) – Flag indicating whether to use RevIN.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em>, </em><em>optional</em>) – The activation function to use. Defaults to ‘’.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments passed to the parent class.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the activation function is not recognized.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Samformer.Samformer.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Samformer.Samformer.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Samformer.Samformer.description">
<span class="sig-name descname"><span class="pre">description</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Can</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">multivariate</span> <span class="pre">output</span> <span class="pre">\nCan</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">future</span> <span class="pre">covariates\nCan</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">categorical</span> <span class="pre">covariates\nCan</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">Quantile</span> <span class="pre">loss</span> <span class="pre">function'</span></em><a class="headerlink" href="#dsipts.models.Samformer.Samformer.description" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.Samformer.Samformer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#dsipts.models.Samformer.Samformer.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forlward method used during the training loop</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – the batch structure. The keys are:
y : the target variable(s). This is always present
x_num_past: the numerical past variables. This is always present
x_num_future: the numerical future variables
x_cat_past: the categorical past variables
x_cat_future: the categorical future variables
idx_target: index of target features in the past array</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output of the mode;</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Samformer.Samformer.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.Samformer.Samformer.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Samformer.Samformer.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.Samformer.Samformer.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Samformer.Samformer.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.Samformer.Samformer.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Samformer.Samformer.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.Samformer.Samformer.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Samformer.Samformer.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Samformer.Samformer.prepare_data_per_node" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Samformer.Samformer.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Samformer.Samformer.training" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-dsipts.models.Simple">
<span id="dsipts-models-simple-module"></span><h2>dsipts.models.Simple module<a class="headerlink" href="#module-dsipts.models.Simple" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.Simple.Simple">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.Simple.</span></span><span class="sig-name descname"><span class="pre">Simple</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'torch.nn.ReLU'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Simple.Simple" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<p>This is the basic model, each model implemented must overwrite the init method and the forward method.
The inference step is optional, by default it uses the forward method but for recurrent
network you should implement your own method</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>verbose</strong> (<em>bool</em>) – Flag to enable verbose logging.</p></li>
<li><p><strong>past_steps</strong> (<em>int</em>) – Number of past time steps to consider.</p></li>
<li><p><strong>future_steps</strong> (<em>int</em>) – Number of future time steps to predict.</p></li>
<li><p><strong>past_channels</strong> (<em>int</em>) – Number of channels in the past input data.</p></li>
<li><p><strong>future_channels</strong> (<em>int</em>) – Number of channels in the future input data.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>embs_past</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of embedding dimensions for past data.</p></li>
<li><p><strong>embs_fut</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of embedding dimensions for future data.</p></li>
<li><p><strong>n_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of classes for classification. Defaults to 0.</p></li>
<li><p><strong>persistence_weight</strong> (<em>float</em><em>, </em><em>optional</em>) – Weight for persistence in loss calculation. Defaults to 0.0.</p></li>
<li><p><strong>loss_type</strong> (<em>str</em><em>, </em><em>optional</em>) – Type of loss function to use (‘l1’ or ‘mse’). Defaults to ‘l1’.</p></li>
<li><p><strong>quantiles</strong> (<em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>) – List of quantiles for quantile loss. Defaults to an empty list.</p></li>
<li><p><strong>reduction_mode</strong> (<em>str</em><em>, </em><em>optional</em>) – Mode for reduction for categorical embedding layer (‘mean’, ‘sum’, ‘none’). Defaults to ‘mean’.</p></li>
<li><p><strong>use_classical_positional_encoder</strong> (<em>bool</em><em>, </em><em>optional</em>) – Flag to use classical positional encoding or using embedding layer also for the positions. Defaults to False.</p></li>
<li><p><strong>emb_dim</strong> (<em>int</em><em>, </em><em>optional</em>) – Dimension of categorical embeddings. Defaults to 16.</p></li>
<li><p><strong>optim</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>None</em><em>]</em><em>, </em><em>optional</em>) – Optimizer type. Defaults to None.</p></li>
<li><p><strong>optim_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – Configuration for the optimizer. Defaults to None.</p></li>
<li><p><strong>scheduler_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – Configuration for the learning rate scheduler. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>AssertionError</strong> – If the number of quantiles is not equal to 3 when quantiles are provided.</p></li>
<li><p><strong>AssertionError</strong> – If the number of output channels is not 1 for classification tasks.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Simple.Simple.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Simple.Simple.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Simple.Simple.description">
<span class="sig-name descname"><span class="pre">description</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Can</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">multivariate</span> <span class="pre">output</span> <span class="pre">\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">future</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">categorical</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">Quantile</span> <span class="pre">loss</span> <span class="pre">function\n</span> <span class="pre">THE</span> <span class="pre">SIMPLE</span> <span class="pre">IMPLEMENTATION</span> <span class="pre">DOES</span> <span class="pre">NOT</span> <span class="pre">USE</span> <span class="pre">CATEGORICAL</span> <span class="pre">NOR</span> <span class="pre">FUTURE</span> <span class="pre">VARIABLES'</span></em><a class="headerlink" href="#dsipts.models.Simple.Simple.description" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.Simple.Simple.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.Simple.Simple.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forlward method used during the training loop</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – the batch structure. The keys are:
y : the target variable(s). This is always present
x_num_past: the numerical past variables. This is always present
x_num_future: the numerical future variables
x_cat_past: the categorical past variables
x_cat_future: the categorical future variables
idx_target: index of target features in the past array</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output of the mode;</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Simple.Simple.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.Simple.Simple.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Simple.Simple.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.Simple.Simple.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Simple.Simple.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.Simple.Simple.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Simple.Simple.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.Simple.Simple.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Simple.Simple.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Simple.Simple.prepare_data_per_node" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.Simple.Simple.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.Simple.Simple.training" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-dsipts.models.TFT">
<span id="dsipts-models-tft-module"></span><h2>dsipts.models.TFT module<a class="headerlink" href="#module-dsipts.models.TFT" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.TFT.TFT">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.TFT.</span></span><span class="sig-name descname"><span class="pre">TFT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers_RNN</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_head</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.TFT.TFT" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<p>Initializes the model for time series forecasting with attention mechanisms and recurrent neural networks.</p>
<p>This model is designed for direct forecasting, allowing for multi-output and multi-horizon predictions. It leverages attention mechanisms to enhance the selection of relevant past time steps and learn long-term dependencies. The architecture includes RNN enrichment, gating mechanisms to minimize the impact of irrelevant variables, and the ability to output prediction intervals through quantile regression.</p>
<p>Key features include:
- Direct Model: Predicts all future steps at once.
- Multi-Output Forecasting: Capable of predicting one or more variables simultaneously.
- Multi-Horizon Forecasting: Predicts variables at multiple future time steps.
- Attention-Based Mechanism: Enhances the selection of relevant past time steps and learns long-term dependencies.
- RNN Enrichment: Utilizes LSTM for initial autoregressive approximation, which is refined by the rest of the network.
- Gating Mechanisms: Reduces the contribution of irrelevant variables.
- Prediction Intervals: Outputs percentiles (e.g., 10th, 50th, 90th) at each time step.</p>
<p>The model also facilitates interpretability by identifying:
- Global importance of variables for both past and future.
- Temporal patterns.
- Significant events.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d_model</strong> (<em>int</em>) – General hidden dimension across the network, adjustable in sub-networks.</p></li>
<li><p><strong>num_layers_RNN</strong> (<em>int</em>) – Number of layers in the recurrent neural network (LSTM).</p></li>
<li><p><strong>d_head</strong> (<em>int</em>) – Dimension of each attention head.</p></li>
<li><p><strong>n_head</strong> (<em>int</em>) – Number of attention heads.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate applied uniformly across all dropout layers.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments for further customization.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TFT.TFT.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.TFT.TFT.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TFT.TFT.description">
<span class="sig-name descname"><span class="pre">description</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Can</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">multivariate</span> <span class="pre">output</span> <span class="pre">\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">future</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">categorical</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">Quantile</span> <span class="pre">loss</span> <span class="pre">function'</span></em><a class="headerlink" href="#dsipts.models.TFT.TFT.description" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.TFT.TFT.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dsipts.models.TFT.TFT.forward" title="Link to this definition">¶</a></dt>
<dd><p>Temporal Fusion Transformer</p>
<p>Collectiong Data
- Extract the autoregressive variable(s)
- Embedding and compute a first approximated prediction
- ‘summary_past’ and ‘summary_fut’ collecting data about past and future
Concatenating on the dimension 2 all different datas, which will be mixed through a MEAN over that imension
Info get from other tensor of the batch taken as input</p>
<p>TFT actual computations
- Residual Connection for y_past and summary_past
- Residual Connection for y_fut and summary_fut
- GRN1 for past and for fut
- ATTENTION(summary_fut, summary_past, y_past)
- Residual Connection for attention itself
- GRN2 for attention
- Residual Connection for attention and summary_fut
- Linear for actual values and reshape</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – Keys used are [‘x_num_past’, ‘idx_target’, ‘x_num_future’, ‘x_cat_past’, ‘x_cat_future’]</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>shape [B, self.future_steps, self.out_channels, self.mul] or [B, self.future_steps, self.out_channels] according to quantiles</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TFT.TFT.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.TFT.TFT.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TFT.TFT.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.TFT.TFT.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TFT.TFT.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.TFT.TFT.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TFT.TFT.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.TFT.TFT.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TFT.TFT.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.TFT.TFT.prepare_data_per_node" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.TFT.TFT.remove_var">
<span class="sig-name descname"><span class="pre">remove_var</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indexes_to_exclude</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dsipts.models.TFT.TFT.remove_var" title="Link to this definition">¶</a></dt>
<dd><p>Function to remove variables from tensors in chosen dimension and position</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> (<em>torch.Tensor</em>) – starting tensor</p></li>
<li><p><strong>indexes_to_exclude</strong> (<em>int</em>) – index of the chosen dimension we want t oexclude</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – dimension of the tensor on which we want to work</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>new tensor without the chosen variables</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TFT.TFT.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.TFT.TFT.training" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-dsipts.models.TIDE">
<span id="dsipts-models-tide-module"></span><h2>dsipts.models.TIDE module<a class="headerlink" href="#module-dsipts.models.TIDE" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.TIDE.ResidualBlock">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.TIDE.</span></span><span class="sig-name descname"><span class="pre">ResidualBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fun</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.TIDE.ResidualBlock" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Residual Block as basic layer of the archetecture.</p>
<p>MLP with one hidden layer, activation and skip connection
Basically dimension d_model, but better if input_dim and output_dim are explicit</p>
<p>in_size and out_size to handle dimensions at different stages of the NN</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_size</strong> (<em>int</em>)</p></li>
<li><p><strong>out_size</strong> (<em>int</em>)</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>)</p></li>
<li><p><strong>activation_fun</strong> (<em>str</em><em>, </em><em>optional</em>) – activation function to use in the Residual Block. Defaults to nn.ReLU.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.TIDE.ResidualBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">apply_final_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.TIDE.ResidualBlock.forward" title="Link to this definition">¶</a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.TIDE.TIDE">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.TIDE.</span></span><span class="sig-name descname"><span class="pre">TIDE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_add_enc</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_add_dec</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.TIDE.TIDE" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<p>Initializes the model with specified parameters for a neural network architecture. Long-term Forecasting with TiDE: Time-series Dense Encoder
<a class="reference external" href="https://arxiv.org/abs/2304.08424">https://arxiv.org/abs/2304.08424</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<em>int</em>) – The size of the hidden layers.</p></li>
<li><p><strong>d_model</strong> (<em>int</em>) – The dimensionality of the model.</p></li>
<li><p><strong>n_add_enc</strong> (<em>int</em>) – The number of additional encoder layers.</p></li>
<li><p><strong>n_add_dec</strong> (<em>int</em>) – The number of additional decoder layers.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – The dropout rate to be applied in the layers.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em>, </em><em>optional</em>) – The activation function to be used. Defaults to an empty string.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments passed to the parent class.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TIDE.TIDE.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.TIDE.TIDE.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TIDE.TIDE.description">
<span class="sig-name descname"><span class="pre">description</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Can</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">multivariate</span> <span class="pre">output</span> <span class="pre">\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">future</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">categorical</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">Quantile</span> <span class="pre">loss</span> <span class="pre">function'</span></em><a class="headerlink" href="#dsipts.models.TIDE.TIDE.description" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.TIDE.TIDE.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#dsipts.models.TIDE.TIDE.forward" title="Link to this definition">¶</a></dt>
<dd><p>training process of the diffusion network</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – variables loaded</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>total loss about the prediction of the noises over all subnets extracted</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TIDE.TIDE.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.TIDE.TIDE.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TIDE.TIDE.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.TIDE.TIDE.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TIDE.TIDE.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.TIDE.TIDE.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TIDE.TIDE.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.TIDE.TIDE.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TIDE.TIDE.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.TIDE.TIDE.prepare_data_per_node" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.TIDE.TIDE.remove_var">
<span class="sig-name descname"><span class="pre">remove_var</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indexes_to_exclude</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dsipts.models.TIDE.TIDE.remove_var" title="Link to this definition">¶</a></dt>
<dd><p>Function to remove variables from tensors in chosen dimension and position</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> (<em>torch.Tensor</em>) – starting tensor</p></li>
<li><p><strong>indexes_to_exclude</strong> (<em>list</em>) – index of the chosen dimension we want t oexclude</p></li>
<li><p><strong>dimension</strong> (<em>int</em>) – dimension of the tensor on which we want to work (not list od dims!!)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>new tensor without the chosen variables</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TIDE.TIDE.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.TIDE.TIDE.training" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-dsipts.models.TTM">
<span id="dsipts-models-ttm-module"></span><h2>dsipts.models.TTM module<a class="headerlink" href="#module-dsipts.models.TTM" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.TTM.TTM">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.TTM.</span></span><span class="sig-name descname"><span class="pre">TTM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">freq_prefix_tuning</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">freq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefer_l1_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefer_longer_context</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_input_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prediction_channel_indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exogenous_channel_indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_mode</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fcm_context_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fcm_use_mixer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fcm_mix_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fcm_prepend_past</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_forecast_channel_mixing</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_last</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optim_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_quantiles</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistence_weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantiles</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.TTM.TTM" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<p>TODO and FIX for future and past categorical variables</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_path</strong> (<em>str</em>) – _description_</p></li>
<li><p><strong>past_steps</strong> (<em>int</em>) – _description_</p></li>
<li><p><strong>future_steps</strong> (<em>int</em>) – _description_</p></li>
<li><p><strong>freq_prefix_tuning</strong> (<em>bool</em>) – _description_</p></li>
<li><p><strong>freq</strong> (<em>str</em>) – _description_</p></li>
<li><p><strong>prefer_l1_loss</strong> (<em>bool</em>) – _description_</p></li>
<li><p><strong>loss_type</strong> (<em>str</em>) – _description_</p></li>
<li><p><strong>num_input_channels</strong> (<em>_type_</em>) – _description_</p></li>
<li><p><strong>prediction_channel_indices</strong> (<em>_type_</em>) – _description_</p></li>
<li><p><strong>exogenous_channel_indices</strong> (<em>_type_</em>) – _description_</p></li>
<li><p><strong>decoder_mode</strong> (<em>_type_</em>) – _description_</p></li>
<li><p><strong>fcm_context_length</strong> (<em>_type_</em>) – _description_</p></li>
<li><p><strong>fcm_use_mixer</strong> (<em>_type_</em>) – _description_</p></li>
<li><p><strong>fcm_mix_layers</strong> (<em>_type_</em>) – _description_</p></li>
<li><p><strong>fcm_prepend_past</strong> (<em>_type_</em>) – _description_</p></li>
<li><p><strong>enable_forecast_channel_mixing</strong> (<em>_type_</em>) – _description_</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – _description_</p></li>
<li><p><strong>embs</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – _description_</p></li>
<li><p><strong>remove_last</strong> (<em>bool</em><em>, </em><em>optional</em>) – _description_. Defaults to False.</p></li>
<li><p><strong>optim</strong> (<em>Union</em><em>[</em><em>str</em><em>,</em><em>None</em><em>]</em><em>, </em><em>optional</em>) – _description_. Defaults to None.</p></li>
<li><p><strong>optim_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – _description_. Defaults to None.</p></li>
<li><p><strong>scheduler_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – _description_. Defaults to None.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>optional</em>) – _description_. Defaults to False.</p></li>
<li><p><strong>use_quantiles</strong> (<em>bool</em><em>, </em><em>optional</em>) – _description_. Defaults to False.</p></li>
<li><p><strong>persistence_weight</strong> (<em>float</em><em>, </em><em>optional</em>) – _description_. Defaults to 0.0.</p></li>
<li><p><strong>quantiles</strong> (<em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>) – _description_. Defaults to [].</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.TTM.TTM.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.TTM.TTM.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forlward method used during the training loop</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – the batch structure. The keys are:
y : the target variable(s). This is always present
x_num_past: the numerical past variables. This is always present
x_num_future: the numerical future variables
x_cat_past: the categorical past variables
x_cat_future: the categorical future variables
idx_target: index of target features in the past array</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output of the mode;</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-dsipts.models.TimeXER">
<span id="dsipts-models-timexer-module"></span><h2>dsipts.models.TimeXER module<a class="headerlink" href="#module-dsipts.models.TimeXER" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.TimeXER.TimeXER">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.TimeXER.</span></span><span class="sig-name descname"><span class="pre">TimeXER</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patch_len</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_ff</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">512</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layer_decoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.TimeXER.TimeXER" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<p>Initialize the model with specified parameters. <a class="reference external" href="https://github.com/thuml/Time-Series-Library/blob/main/models/TimeMixer.py">https://github.com/thuml/Time-Series-Library/blob/main/models/TimeMixer.py</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>patch_len</strong> (<em>int</em>) – Length of the patches.</p></li>
<li><p><strong>d_model</strong> (<em>int</em>) – Dimension of the model.</p></li>
<li><p><strong>n_head</strong> (<em>int</em>) – Number of attention heads.</p></li>
<li><p><strong>d_ff</strong> (<em>int</em><em>, </em><em>optional</em>) – Dimension of the feedforward network. Defaults to 512.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – Dropout rate for regularization. Defaults to 0.1.</p></li>
<li><p><strong>n_layer_decoder</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of layers in the decoder. Defaults to 1.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em>, </em><em>optional</em>) – Activation function to use. Defaults to ‘’.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments passed to the superclass.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If an invalid activation function is provided.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TimeXER.TimeXER.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.TimeXER.TimeXER.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TimeXER.TimeXER.description">
<span class="sig-name descname"><span class="pre">description</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Can</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">multivariate</span> <span class="pre">output</span> <span class="pre">\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">future</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">categorical</span> <span class="pre">covariates\nCan</span>&#160;&#160; <span class="pre">handle</span> <span class="pre">Quantile</span> <span class="pre">loss</span> <span class="pre">function'</span></em><a class="headerlink" href="#dsipts.models.TimeXER.TimeXER.description" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.TimeXER.TimeXER.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#dsipts.models.TimeXER.TimeXER.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forlward method used during the training loop</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – the batch structure. The keys are:
y : the target variable(s). This is always present
x_num_past: the numerical past variables. This is always present
x_num_future: the numerical future variables
x_cat_past: the categorical past variables
x_cat_future: the categorical future variables
idx_target: index of target features in the past array</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output of the mode;</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TimeXER.TimeXER.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.TimeXER.TimeXER.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TimeXER.TimeXER.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.TimeXER.TimeXER.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TimeXER.TimeXER.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.TimeXER.TimeXER.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TimeXER.TimeXER.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#dsipts.models.TimeXER.TimeXER.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TimeXER.TimeXER.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.TimeXER.TimeXER.prepare_data_per_node" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.TimeXER.TimeXER.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.TimeXER.TimeXER.training" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-dsipts.models.VQVAEA">
<span id="dsipts-models-vqvaea-module"></span><h2>dsipts.models.VQVAEA module<a class="headerlink" href="#module-dsipts.models.VQVAEA" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.VQVAEA.VQVAEA">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.VQVAEA.</span></span><span class="sig-name descname"><span class="pre">VQVAEA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">past_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_voc_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">commitment_cost</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decay</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_heads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch_vqvae</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistence_weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'l1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantiles</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optim_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.VQVAEA.VQVAEA" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<p>Custom encoder-decoder</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>past_steps</strong> (<em>int</em>) – number of past datapoints used</p></li>
<li><p><strong>future_steps</strong> (<em>int</em>) – number of future lag to predict</p></li>
<li><p><strong>past_channels</strong> (<em>int</em>) – number of numeric past variables, must be &gt;0</p></li>
<li><p><strong>future_channels</strong> (<em>int</em>) – number of future numeric variables</p></li>
<li><p><strong>embs</strong> (<em>List</em>) – list of the initial dimension of the categorical variables</p></li>
<li><p><strong>cat_emb_dim</strong> (<em>int</em>) – final dimension of each categorical variable</p></li>
<li><p><strong>hidden_RNN</strong> (<em>int</em>) – hidden size of the RNN block</p></li>
<li><p><strong>num_layers_RNN</strong> (<em>int</em>) – number of RNN layers</p></li>
<li><p><strong>kind</strong> (<em>str</em>) – one among GRU or LSTM</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size in the encoder convolutional block</p></li>
<li><p><strong>sum_emb</strong> (<em>bool</em>) – if true the contribution of each embedding will be summed-up otherwise stacked</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – number of output channels</p></li>
<li><p><strong>activation</strong> (<em>str</em><em>, </em><em>optional</em>) – activation fuction function pytorch. Default torch.nn.ReLU</p></li>
<li><p><strong>remove_last</strong> (<em>bool</em><em>, </em><em>optional</em>) – if True the model learns the difference respect to the last seen point</p></li>
<li><p><strong>persistence_weight</strong> (<em>float</em>) – weight controlling the divergence from persistence model. Default 0</p></li>
<li><p><strong>loss_type</strong> (<em>str</em><em>, </em><em>optional</em>) – this model uses custom losses or l1 or mse. Custom losses can be linear_penalization or exponential_penalization. Default l1,</p></li>
<li><p><strong>quantiles</strong> (<em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>) – we can use quantile loss il len(quantiles) = 0 (usually 0.1,0.5, 0.9) or L1loss in case len(quantiles)==0. Defaults to [].</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – dropout rate in Dropout layers</p></li>
<li><p><strong>use_bn</strong> (<em>bool</em><em>, </em><em>optional</em>) – if true BN layers will be added and dropouts will be removed</p></li>
<li><p><strong>use_glu</strong> (<em>bool</em><em>,</em><em>optional</em>) – use GLU for feature selection. Defaults to True.</p></li>
<li><p><strong>glu_percentage</strong> (<em>float</em><em>, </em><em>optiona</em>) – percentage of features to use. Defaults to 1.0.</p></li>
<li><p><strong>n_classes</strong> (<em>int</em>) – number of classes (0 in regression)</p></li>
<li><p><strong>optim</strong> (<em>str</em><em>, </em><em>optional</em>) – if not None it expects a pytorch optim method. Defaults to None that is mapped to Adam.</p></li>
<li><p><strong>optim_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – configuration for Adam optimizer. Defaults to None.</p></li>
<li><p><strong>scheduler_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – configuration for stepLR scheduler. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.VQVAEA.VQVAEA.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.VQVAEA.VQVAEA.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.VQVAEA.VQVAEA.description">
<span class="sig-name descname"><span class="pre">description</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Can</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">multivariate</span> <span class="pre">output</span> <span class="pre">\nCan</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">future</span> <span class="pre">covariates\nCan</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">categorical</span> <span class="pre">covariates\nCan</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">Quantile</span> <span class="pre">loss</span> <span class="pre">function'</span></em><a class="headerlink" href="#dsipts.models.VQVAEA.VQVAEA.description" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.VQVAEA.VQVAEA.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.VQVAEA.VQVAEA.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forlward method used during the training loop</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – the batch structure. The keys are:
y : the target variable(s). This is always present
x_num_past: the numerical past variables. This is always present
x_num_future: the numerical future variables
x_cat_past: the categorical past variables
x_cat_future: the categorical future variables
idx_target: index of target features in the past array</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output of the mode;</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.VQVAEA.VQVAEA.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_new_tokens</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">do_sample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.VQVAEA.VQVAEA.generate" title="Link to this definition">¶</a></dt>
<dd><p>Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete
the sequence max_new_tokens times, feeding the predictions back into the model each time.
Most likely you’ll want to make sure to be in model.eval() mode of operation for this.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.VQVAEA.VQVAEA.gpt">
<span class="sig-name descname"><span class="pre">gpt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tokens</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.VQVAEA.VQVAEA.gpt" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.VQVAEA.VQVAEA.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.VQVAEA.VQVAEA.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.VQVAEA.VQVAEA.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.VQVAEA.VQVAEA.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.VQVAEA.VQVAEA.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.VQVAEA.VQVAEA.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.VQVAEA.VQVAEA.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.VQVAEA.VQVAEA.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.VQVAEA.VQVAEA.inference">
<span class="sig-name descname"><span class="pre">inference</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tensor</span></span></span><a class="headerlink" href="#dsipts.models.VQVAEA.VQVAEA.inference" title="Link to this definition">¶</a></dt>
<dd><p>Usually it is ok to return the output of the forward method but sometimes not (e.g. RNN)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – batch</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>result</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.VQVAEA.VQVAEA.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.VQVAEA.VQVAEA.prepare_data_per_node" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.VQVAEA.VQVAEA.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.VQVAEA.VQVAEA.training" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dsipts.models.VQVAEA.random">
<span class="sig-prename descclassname"><span class="pre">dsipts.models.VQVAEA.</span></span><span class="sig-name descname"><span class="pre">random</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">x</span> <span class="pre">in</span> <span class="pre">the</span> <span class="pre">interval</span> <span class="pre">[0,</span> <span class="pre">1).</span></span></span><a class="headerlink" href="#dsipts.models.VQVAEA.random" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="module-dsipts.models.VVA">
<span id="dsipts-models-vva-module"></span><h2>dsipts.models.VVA module<a class="headerlink" href="#module-dsipts.models.VVA" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.VVA.VVA">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.VVA.</span></span><span class="sig-name descname"><span class="pre">VVA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">past_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_voc_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_split</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_heads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistence_weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'l1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantiles</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optim_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.VVA.VVA" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dsipts.models.base_v2.Base" title="dsipts.models.base_v2.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">Base</span></code></a></p>
<p>Custom encoder-decoder</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>past_steps</strong> (<em>int</em>) – number of past datapoints used</p></li>
<li><p><strong>future_steps</strong> (<em>int</em>) – number of future lag to predict</p></li>
<li><p><strong>past_channels</strong> (<em>int</em>) – number of numeric past variables, must be &gt;0</p></li>
<li><p><strong>future_channels</strong> (<em>int</em>) – number of future numeric variables</p></li>
<li><p><strong>embs</strong> (<em>List</em>) – list of the initial dimension of the categorical variables</p></li>
<li><p><strong>cat_emb_dim</strong> (<em>int</em>) – final dimension of each categorical variable</p></li>
<li><p><strong>hidden_RNN</strong> (<em>int</em>) – hidden size of the RNN block</p></li>
<li><p><strong>num_layers_RNN</strong> (<em>int</em>) – number of RNN layers</p></li>
<li><p><strong>kind</strong> (<em>str</em>) – one among GRU or LSTM</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size in the encoder convolutional block</p></li>
<li><p><strong>sum_emb</strong> (<em>bool</em>) – if true the contribution of each embedding will be summed-up otherwise stacked</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – number of output channels</p></li>
<li><p><strong>activation</strong> (<em>str</em><em>, </em><em>optional</em>) – activation fuction function pytorch. Default torch.nn.ReLU</p></li>
<li><p><strong>remove_last</strong> (<em>bool</em><em>, </em><em>optional</em>) – if True the model learns the difference respect to the last seen point</p></li>
<li><p><strong>persistence_weight</strong> (<em>float</em>) – weight controlling the divergence from persistence model. Default 0</p></li>
<li><p><strong>loss_type</strong> (<em>str</em><em>, </em><em>optional</em>) – this model uses custom losses or l1 or mse. Custom losses can be linear_penalization or exponential_penalization. Default l1,</p></li>
<li><p><strong>quantiles</strong> (<em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>) – we can use quantile loss il len(quantiles) = 0 (usually 0.1,0.5, 0.9) or L1loss in case len(quantiles)==0. Defaults to [].</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – dropout rate in Dropout layers</p></li>
<li><p><strong>use_bn</strong> (<em>bool</em><em>, </em><em>optional</em>) – if true BN layers will be added and dropouts will be removed</p></li>
<li><p><strong>use_glu</strong> (<em>bool</em><em>,</em><em>optional</em>) – use GLU for feature selection. Defaults to True.</p></li>
<li><p><strong>glu_percentage</strong> (<em>float</em><em>, </em><em>optiona</em>) – percentage of features to use. Defaults to 1.0.</p></li>
<li><p><strong>n_classes</strong> (<em>int</em>) – number of classes (0 in regression)</p></li>
<li><p><strong>optim</strong> (<em>str</em><em>, </em><em>optional</em>) – if not None it expects a pytorch optim method. Defaults to None that is mapped to Adam.</p></li>
<li><p><strong>optim_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – configuration for Adam optimizer. Defaults to None.</p></li>
<li><p><strong>scheduler_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – configuration for stepLR scheduler. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.VVA.VVA.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.VVA.VVA.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.VVA.VVA.configure_optimizers">
<span class="sig-name descname"><span class="pre">configure_optimizers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.VVA.VVA.configure_optimizers" title="Link to this definition">¶</a></dt>
<dd><p>This long function is unfortunately doing something very simple and is being very defensive:
We are separating out all parameters of the model into two buckets: those that will experience
weight decay for regularization and those that won’t (biases, and layernorm/embedding weights).
We are then returning the PyTorch optimizer object.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.VVA.VVA.description">
<span class="sig-name descname"><span class="pre">description</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Can</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">multivariate</span> <span class="pre">output</span> <span class="pre">\nCan</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">future</span> <span class="pre">covariates\nCan</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">categorical</span> <span class="pre">covariates\nCan</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">Quantile</span> <span class="pre">loss</span> <span class="pre">function'</span></em><a class="headerlink" href="#dsipts.models.VVA.VVA.description" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.VVA.VVA.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.VVA.VVA.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forlward method used during the training loop</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – the batch structure. The keys are:
y : the target variable(s). This is always present
x_num_past: the numerical past variables. This is always present
x_num_future: the numerical future variables
x_cat_past: the categorical past variables
x_cat_future: the categorical future variables
idx_target: index of target features in the past array</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output of the mode;</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.VVA.VVA.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_new_tokens</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">do_sample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.VVA.VVA.generate" title="Link to this definition">¶</a></dt>
<dd><p>Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete
the sequence max_new_tokens times, feeding the predictions back into the model each time.
Most likely you’ll want to make sure to be in model.eval() mode of operation for this.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.VVA.VVA.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.VVA.VVA.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.VVA.VVA.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.VVA.VVA.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.VVA.VVA.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.VVA.VVA.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.VVA.VVA.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.VVA.VVA.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.VVA.VVA.inference">
<span class="sig-name descname"><span class="pre">inference</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tensor</span></span></span><a class="headerlink" href="#dsipts.models.VVA.VVA.inference" title="Link to this definition">¶</a></dt>
<dd><p>Usually it is ok to return the output of the forward method but sometimes not (e.g. RNN)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – batch</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>result</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.VVA.VVA.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.VVA.VVA.prepare_data_per_node" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.VVA.VVA.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.VVA.VVA.training" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-dsipts.models.base">
<span id="dsipts-models-base-module"></span><h2>dsipts.models.base module<a class="headerlink" href="#module-dsipts.models.base" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.base.Base">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.base.</span></span><span class="sig-name descname"><span class="pre">Base</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs_past</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs_fut</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_classes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistence_weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'l1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantiles</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_classical_positional_encoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optim_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.base.Base" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code></p>
<p>This is the basic model, each model implemented must overwrite the init method and the forward method.
The inference step is optional, by default it uses the forward method but for recurrent
network you should implement your own method</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>verbose</strong> (<em>bool</em>) – Flag to enable verbose logging.</p></li>
<li><p><strong>past_steps</strong> (<em>int</em>) – Number of past time steps to consider.</p></li>
<li><p><strong>future_steps</strong> (<em>int</em>) – Number of future time steps to predict.</p></li>
<li><p><strong>past_channels</strong> (<em>int</em>) – Number of channels in the past input data.</p></li>
<li><p><strong>future_channels</strong> (<em>int</em>) – Number of channels in the future input data.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>embs_past</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of embedding dimensions for past data.</p></li>
<li><p><strong>embs_fut</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of embedding dimensions for future data.</p></li>
<li><p><strong>n_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of classes for classification. Defaults to 0.</p></li>
<li><p><strong>persistence_weight</strong> (<em>float</em><em>, </em><em>optional</em>) – Weight for persistence in loss calculation. Defaults to 0.0.</p></li>
<li><p><strong>loss_type</strong> (<em>str</em><em>, </em><em>optional</em>) – Type of loss function to use (‘l1’ or ‘mse’). Defaults to ‘l1’.</p></li>
<li><p><strong>quantiles</strong> (<em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>) – List of quantiles for quantile loss. Defaults to an empty list.</p></li>
<li><p><strong>reduction_mode</strong> (<em>str</em><em>, </em><em>optional</em>) – Mode for reduction for categorical embedding layer (‘mean’, ‘sum’, ‘none’). Defaults to ‘mean’.</p></li>
<li><p><strong>use_classical_positional_encoder</strong> (<em>bool</em><em>, </em><em>optional</em>) – Flag to use classical positional encoding or using embedding layer also for the positions. Defaults to False.</p></li>
<li><p><strong>emb_dim</strong> (<em>int</em><em>, </em><em>optional</em>) – Dimension of categorical embeddings. Defaults to 16.</p></li>
<li><p><strong>optim</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>None</em><em>]</em><em>, </em><em>optional</em>) – Optimizer type. Defaults to None.</p></li>
<li><p><strong>optim_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – Configuration for the optimizer. Defaults to None.</p></li>
<li><p><strong>scheduler_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – Configuration for the learning rate scheduler. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>AssertionError</strong> – If the number of quantiles is not equal to 3 when quantiles are provided.</p></li>
<li><p><strong>AssertionError</strong> – If the number of output channels is not 1 for classification tasks.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.base.Base.description">
<span class="sig-name descname"><span class="pre">description</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Can</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">multivariate</span> <span class="pre">output</span> <span class="pre">\nCan</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">future</span> <span class="pre">covariates\nCan</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">categorical</span> <span class="pre">covariates\nCan</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">Quantile</span> <span class="pre">loss</span> <span class="pre">function'</span></em><a class="headerlink" href="#dsipts.models.base.Base.description" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.base.Base.forward">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tensor</span></span></span><a class="headerlink" href="#dsipts.models.base.Base.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forlward method used during the training loop</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – the batch structure. The keys are:
y : the target variable(s). This is always present
x_num_past: the numerical past variables. This is always present
x_num_future: the numerical future variables
x_cat_past: the categorical past variables
x_cat_future: the categorical future variables
idx_target: index of target features in the past array</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output of the mode;</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.base.Base.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.base.Base.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.base.Base.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.base.Base.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.base.Base.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.base.Base.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.base.Base.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.base.Base.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.base.Base.inference">
<span class="sig-name descname"><span class="pre">inference</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tensor</span></span></span><a class="headerlink" href="#dsipts.models.base.Base.inference" title="Link to this definition">¶</a></dt>
<dd><p>Usually it is ok to return the output of the forward method but sometimes not (e.g. RNN)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – batch</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>result</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dsipts.models.base.dilate_loss">
<span class="sig-prename descclassname"><span class="pre">dsipts.models.base.</span></span><span class="sig-name descname"><span class="pre">dilate_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.base.dilate_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dsipts.models.base.standardize_momentum">
<span class="sig-prename descclassname"><span class="pre">dsipts.models.base.</span></span><span class="sig-name descname"><span class="pre">standardize_momentum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">order</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.base.standardize_momentum" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="module-dsipts.models.base_v2">
<span id="dsipts-models-base-v2-module"></span><h2>dsipts.models.base_v2 module<a class="headerlink" href="#module-dsipts.models.base_v2" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.base_v2.Base">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.base_v2.</span></span><span class="sig-name descname"><span class="pre">Base</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs_past</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs_fut</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_classes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistence_weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'l1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantiles</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_classical_positional_encoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optim_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.base_v2.Base" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code></p>
<p>This is the basic model, each model implemented must overwrite the init method and the forward method.
The inference step is optional, by default it uses the forward method but for recurrent
network you should implement your own method</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>verbose</strong> (<em>bool</em>) – Flag to enable verbose logging.</p></li>
<li><p><strong>past_steps</strong> (<em>int</em>) – Number of past time steps to consider.</p></li>
<li><p><strong>future_steps</strong> (<em>int</em>) – Number of future time steps to predict.</p></li>
<li><p><strong>past_channels</strong> (<em>int</em>) – Number of channels in the past input data.</p></li>
<li><p><strong>future_channels</strong> (<em>int</em>) – Number of channels in the future input data.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>embs_past</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of embedding dimensions for past data.</p></li>
<li><p><strong>embs_fut</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of embedding dimensions for future data.</p></li>
<li><p><strong>n_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of classes for classification. Defaults to 0.</p></li>
<li><p><strong>persistence_weight</strong> (<em>float</em><em>, </em><em>optional</em>) – Weight for persistence in loss calculation. Defaults to 0.0.</p></li>
<li><p><strong>loss_type</strong> (<em>str</em><em>, </em><em>optional</em>) – Type of loss function to use (‘l1’ or ‘mse’). Defaults to ‘l1’.</p></li>
<li><p><strong>quantiles</strong> (<em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>) – List of quantiles for quantile loss. Defaults to an empty list.</p></li>
<li><p><strong>reduction_mode</strong> (<em>str</em><em>, </em><em>optional</em>) – Mode for reduction for categorical embedding layer (‘mean’, ‘sum’, ‘none’). Defaults to ‘mean’.</p></li>
<li><p><strong>use_classical_positional_encoder</strong> (<em>bool</em><em>, </em><em>optional</em>) – Flag to use classical positional encoding or using embedding layer also for the positions. Defaults to False.</p></li>
<li><p><strong>emb_dim</strong> (<em>int</em><em>, </em><em>optional</em>) – Dimension of categorical embeddings. Defaults to 16.</p></li>
<li><p><strong>optim</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>None</em><em>]</em><em>, </em><em>optional</em>) – Optimizer type. Defaults to None.</p></li>
<li><p><strong>optim_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – Configuration for the optimizer. Defaults to None.</p></li>
<li><p><strong>scheduler_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – Configuration for the learning rate scheduler. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>AssertionError</strong> – If the number of quantiles is not equal to 3 when quantiles are provided.</p></li>
<li><p><strong>AssertionError</strong> – If the number of output channels is not 1 for classification tasks.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.base_v2.Base.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.base_v2.Base.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.base_v2.Base.description">
<span class="sig-name descname"><span class="pre">description</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Can</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">multivariate</span> <span class="pre">output</span> <span class="pre">\nCan</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">future</span> <span class="pre">covariates\nCan</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">categorical</span> <span class="pre">covariates\nCan</span> <span class="pre">NOT</span>&#160; <span class="pre">handle</span> <span class="pre">Quantile</span> <span class="pre">loss</span> <span class="pre">function'</span></em><a class="headerlink" href="#dsipts.models.base_v2.Base.description" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.base_v2.Base.forward">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tensor</span></span></span><a class="headerlink" href="#dsipts.models.base_v2.Base.forward" title="Link to this definition">¶</a></dt>
<dd><p>Forlward method used during the training loop</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – the batch structure. The keys are:
y : the target variable(s). This is always present
x_num_past: the numerical past variables. This is always present
x_num_future: the numerical future variables
x_cat_past: the categorical past variables
x_cat_future: the categorical future variables
idx_target: index of target features in the past array</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output of the mode;</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.base_v2.Base.handle_categorical_variables">
<span class="sig-name descname"><span class="pre">handle_categorical_variables</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.base_v2.Base.handle_categorical_variables" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.base_v2.Base.handle_future_covariates">
<span class="sig-name descname"><span class="pre">handle_future_covariates</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.base_v2.Base.handle_future_covariates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.base_v2.Base.handle_multivariate">
<span class="sig-name descname"><span class="pre">handle_multivariate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.base_v2.Base.handle_multivariate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.base_v2.Base.handle_quantile_loss">
<span class="sig-name descname"><span class="pre">handle_quantile_loss</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#dsipts.models.base_v2.Base.handle_quantile_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.base_v2.Base.inference">
<span class="sig-name descname"><span class="pre">inference</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tensor</span></span></span><a class="headerlink" href="#dsipts.models.base_v2.Base.inference" title="Link to this definition">¶</a></dt>
<dd><p>Usually it is ok to return the output of the forward method but sometimes not (e.g. RNN)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>dict</em>) – batch</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>result</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.base_v2.Base.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.base_v2.Base.prepare_data_per_node" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dsipts.models.base_v2.Base.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#dsipts.models.base_v2.Base.training" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dsipts.models.base_v2.dilate_loss">
<span class="sig-prename descclassname"><span class="pre">dsipts.models.base_v2.</span></span><span class="sig-name descname"><span class="pre">dilate_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.base_v2.dilate_loss" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dsipts.models.base_v2.standardize_momentum">
<span class="sig-prename descclassname"><span class="pre">dsipts.models.base_v2.</span></span><span class="sig-name descname"><span class="pre">standardize_momentum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">order</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.base_v2.standardize_momentum" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="module-dsipts.models.utils">
<span id="dsipts-models-utils-module"></span><h2>dsipts.models.utils module<a class="headerlink" href="#module-dsipts.models.utils" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.utils.CPRS">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">CPRS</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.CPRS" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.utils.CPRS.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_hat</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.CPRS.forward" title="Link to this definition">¶</a></dt>
<dd><p>Compute the almost fair CRPS loss (efficient version).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ensemble</strong> – Tensor of shape (batch_size, n_members, …)</p></li>
<li><p><strong>target</strong> – Tensor of shape (batch_size, …)</p></li>
<li><p><strong>weights</strong> – Optional per-variable or per-location weights</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Loss tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.utils.Embedding_cat_variables">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">Embedding_cat_variables</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_classical_positional_encoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.Embedding_cat_variables" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Embeds categorical variables with optional positional encodings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>length</strong> (<em>int</em>) – Sequence length (e.g., total time steps).</p></li>
<li><p><strong>d_model</strong> (<em>int</em>) – Output embedding dimension.</p></li>
<li><p><strong>emb_dims</strong> (<em>list</em>) – Vocabulary sizes for each categorical feature.</p></li>
<li><p><strong>reduction_mode</strong> (<em>str</em>) – ‘mean’, ‘sum’, or ‘none’.</p></li>
<li><p><strong>use_classical_positional_encoder</strong> (<em>bool</em>) – Whether to use sinusoidal positional encoding.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Device name (e.g., ‘cpu’ or ‘cuda’).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>If <cite>reduction_mode</cite> is ‘none’, all embeddings are concatenated.</p></li>
<li><p>If <cite>use_classical_positional_encoder</cite> is True, uses fixed sin/cos encoding.</p></li>
<li><p>If False, treats position as a categorical variable and embeds it.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.utils.Embedding_cat_variables.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">BS</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dsipts.models.utils.Embedding_cat_variables.forward" title="Link to this definition">¶</a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.utils.Embedding_cat_variables.get_cat_n_embd">
<span class="sig-name descname"><span class="pre">get_cat_n_embd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cat_vars</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.Embedding_cat_variables.get_cat_n_embd" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.utils.L1Loss">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">L1Loss</span></span><a class="headerlink" href="#dsipts.models.utils.L1Loss" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.utils.L1Loss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">preds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.L1Loss.forward" title="Link to this definition">¶</a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.utils.PathDTWBatch">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">PathDTWBatch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.PathDTWBatch" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Function</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.utils.PathDTWBatch.backward">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad_output</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.PathDTWBatch.backward" title="Link to this definition">¶</a></dt>
<dd><p>Define a formula for differentiating the operation with backward mode automatic differentiation.</p>
<p>This function is to be overridden by all subclasses.
(Defining this function is equivalent to defining the <code class="docutils literal notranslate"><span class="pre">vjp</span></code> function.)</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs as the <a class="reference internal" href="#dsipts.models.utils.PathDTWBatch.forward" title="dsipts.models.utils.PathDTWBatch.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> returned (None will be passed in
for non tensor outputs of the forward function),
and it should return as many tensors, as there were inputs to
<a class="reference internal" href="#dsipts.models.utils.PathDTWBatch.forward" title="dsipts.models.utils.PathDTWBatch.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the gradient w.r.t the given output,
and each returned value should be the gradient w.r.t. the
corresponding input. If an input is not a Tensor or is a Tensor not
requiring grads, you can just pass None as a gradient for that input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#dsipts.models.utils.PathDTWBatch.backward" title="dsipts.models.utils.PathDTWBatch.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#dsipts.models.utils.PathDTWBatch.forward" title="dsipts.models.utils.PathDTWBatch.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computed w.r.t. the
output.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.utils.PathDTWBatch.forward">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">D</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.PathDTWBatch.forward" title="Link to this definition">¶</a></dt>
<dd><p>Define the forward of the custom autograd Function.</p>
<p>This function is to be overridden by all subclasses.
There are two ways to define forward:</p>
<p>Usage 1 (Combined forward and ctx):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="k">pass</span>
</pre></div>
</div>
<ul class="simple">
<li><p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p></li>
<li><p>See <span class="xref std std-ref">combining-forward-context</span> for more details</p></li>
</ul>
<p>Usage 2 (Separate forward and ctx):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">setup_context</span><span class="p">(</span><span class="n">ctx</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">output</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">pass</span>
</pre></div>
</div>
<ul class="simple">
<li><p>The forward no longer accepts a ctx argument.</p></li>
<li><p>Instead, you must also override the <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.autograd.Function.setup_context()</span></code>
staticmethod to handle setting up the <code class="docutils literal notranslate"><span class="pre">ctx</span></code> object.
<code class="docutils literal notranslate"><span class="pre">output</span></code> is the output of the forward, <code class="docutils literal notranslate"><span class="pre">inputs</span></code> are a Tuple of inputs
to the forward.</p></li>
<li><p>See <span class="xref std std-ref">extending-autograd</span> for more details</p></li>
</ul>
<p>The context can be used to store arbitrary data that can be then
retrieved during the backward pass. Tensors should not be stored
directly on <cite>ctx</cite> (though this is not currently enforced for
backward compatibility). Instead, tensors should be saved either with
<code class="xref py py-func docutils literal notranslate"><span class="pre">ctx.save_for_backward()</span></code> if they are intended to be used in
<code class="docutils literal notranslate"><span class="pre">backward</span></code> (equivalently, <code class="docutils literal notranslate"><span class="pre">vjp</span></code>) or <code class="xref py py-func docutils literal notranslate"><span class="pre">ctx.save_for_forward()</span></code>
if they are intended to be used for in <code class="docutils literal notranslate"><span class="pre">jvp</span></code>.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.utils.Permute">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">Permute</span></span><a class="headerlink" href="#dsipts.models.utils.Permute" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.utils.Permute.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.Permute.forward" title="Link to this definition">¶</a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.utils.QuantileLossMO">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">QuantileLossMO</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">quantiles</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.QuantileLossMO" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.utils.QuantileLossMO.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">preds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.QuantileLossMO.forward" title="Link to this definition">¶</a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.utils.SinkhornDistance">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">SinkhornDistance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">eps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'none'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.SinkhornDistance" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Given two empirical measures each with <span class="math notranslate nohighlight">\(P_1\)</span> locations
<span class="math notranslate nohighlight">\(x\in\mathbb{R}^{D_1}\)</span> and <span class="math notranslate nohighlight">\(P_2\)</span> locations <span class="math notranslate nohighlight">\(y\in\mathbb{R}^{D_2}\)</span>,
outputs an approximation of the regularized OT cost for point clouds.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eps</strong> (<em>float</em>) – regularization coefficient</p></li>
<li><p><strong>max_iter</strong> (<em>int</em>) – maximum number of Sinkhorn iterations</p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
‘none’ | ‘mean’ | ‘sum’. ‘none’: no reduction will be applied,
‘mean’: the sum of the output will be divided by the number of
elements in the output, ‘sum’: the output will be summed. Default: ‘none’</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((N, P_1, D_1)\)</span>, <span class="math notranslate nohighlight">\((N, P_2, D_2)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((N)\)</span> or <span class="math notranslate nohighlight">\(()\)</span>, depending on <cite>reduction</cite></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.utils.SinkhornDistance.M">
<span class="sig-name descname"><span class="pre">M</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">u</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.SinkhornDistance.M" title="Link to this definition">¶</a></dt>
<dd><p>Modified cost for logarithmic updates</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.utils.SinkhornDistance.ave">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">ave</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">u1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.SinkhornDistance.ave" title="Link to this definition">¶</a></dt>
<dd><p>Barycenter subroutine, used by kinetic acceleration through extrapolation.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.utils.SinkhornDistance.compute">
<span class="sig-name descname"><span class="pre">compute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.SinkhornDistance.compute" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dsipts.models.utils.SoftDTWBatch">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">SoftDTWBatch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.SoftDTWBatch" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Function</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.utils.SoftDTWBatch.backward">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad_output</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.SoftDTWBatch.backward" title="Link to this definition">¶</a></dt>
<dd><p>Define a formula for differentiating the operation with backward mode automatic differentiation.</p>
<p>This function is to be overridden by all subclasses.
(Defining this function is equivalent to defining the <code class="docutils literal notranslate"><span class="pre">vjp</span></code> function.)</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs as the <a class="reference internal" href="#dsipts.models.utils.SoftDTWBatch.forward" title="dsipts.models.utils.SoftDTWBatch.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> returned (None will be passed in
for non tensor outputs of the forward function),
and it should return as many tensors, as there were inputs to
<a class="reference internal" href="#dsipts.models.utils.SoftDTWBatch.forward" title="dsipts.models.utils.SoftDTWBatch.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the gradient w.r.t the given output,
and each returned value should be the gradient w.r.t. the
corresponding input. If an input is not a Tensor or is a Tensor not
requiring grads, you can just pass None as a gradient for that input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#dsipts.models.utils.SoftDTWBatch.backward" title="dsipts.models.utils.SoftDTWBatch.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#dsipts.models.utils.SoftDTWBatch.forward" title="dsipts.models.utils.SoftDTWBatch.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computed w.r.t. the
output.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dsipts.models.utils.SoftDTWBatch.forward">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">D</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.SoftDTWBatch.forward" title="Link to this definition">¶</a></dt>
<dd><p>Define the forward of the custom autograd Function.</p>
<p>This function is to be overridden by all subclasses.
There are two ways to define forward:</p>
<p>Usage 1 (Combined forward and ctx):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="k">pass</span>
</pre></div>
</div>
<ul class="simple">
<li><p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p></li>
<li><p>See <span class="xref std std-ref">combining-forward-context</span> for more details</p></li>
</ul>
<p>Usage 2 (Separate forward and ctx):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">setup_context</span><span class="p">(</span><span class="n">ctx</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">output</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">pass</span>
</pre></div>
</div>
<ul class="simple">
<li><p>The forward no longer accepts a ctx argument.</p></li>
<li><p>Instead, you must also override the <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.autograd.Function.setup_context()</span></code>
staticmethod to handle setting up the <code class="docutils literal notranslate"><span class="pre">ctx</span></code> object.
<code class="docutils literal notranslate"><span class="pre">output</span></code> is the output of the forward, <code class="docutils literal notranslate"><span class="pre">inputs</span></code> are a Tuple of inputs
to the forward.</p></li>
<li><p>See <span class="xref std std-ref">extending-autograd</span> for more details</p></li>
</ul>
<p>The context can be used to store arbitrary data that can be then
retrieved during the backward pass. Tensors should not be stored
directly on <cite>ctx</cite> (though this is not currently enforced for
backward compatibility). Instead, tensors should be saved either with
<code class="xref py py-func docutils literal notranslate"><span class="pre">ctx.save_for_backward()</span></code> if they are intended to be used in
<code class="docutils literal notranslate"><span class="pre">backward</span></code> (equivalently, <code class="docutils literal notranslate"><span class="pre">vjp</span></code>) or <code class="xref py py-func docutils literal notranslate"><span class="pre">ctx.save_for_forward()</span></code>
if they are intended to be used for in <code class="docutils literal notranslate"><span class="pre">jvp</span></code>.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dsipts.models.utils.compute_softdtw">
<span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">compute_softdtw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">D</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.compute_softdtw" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dsipts.models.utils.compute_softdtw_backward">
<span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">compute_softdtw_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">D_</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">R</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.compute_softdtw_backward" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dsipts.models.utils.dtw_grad">
<span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">dtw_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.dtw_grad" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dsipts.models.utils.dtw_hessian_prod">
<span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">dtw_hessian_prod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">E</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.dtw_hessian_prod" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dsipts.models.utils.get_activation">
<span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">get_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">activation</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.get_activation" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dsipts.models.utils.get_scope">
<span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">get_scope</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">handle_multivariate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">handle_future_covariates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">handle_categorical_variables</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">handle_quantile_loss</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.get_scope" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dsipts.models.utils.my_max">
<span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">my_max</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.my_max" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dsipts.models.utils.my_max_hessian_product">
<span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">my_max_hessian_product</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.my_max_hessian_product" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dsipts.models.utils.my_min">
<span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">my_min</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.my_min" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dsipts.models.utils.my_min_hessian_product">
<span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">my_min_hessian_product</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.my_min_hessian_product" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dsipts.models.utils.pairwise_distances">
<span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">pairwise_distances</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.pairwise_distances" title="Link to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Input: x is a Nxd matrix</dt><dd><p>y is an optional Mxd matirx</p>
</dd>
<dt>Output: dist is a NxM matrix where dist[i,j] is the square norm between x[i,:] and y[j,:]</dt><dd><p>if y is not given then use ‘y=x’.</p>
</dd>
</dl>
<p>i.e. dist[i,j] = ||x[i,:]-y[j,:]||^2</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dsipts.models.utils.weight_init">
<span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">weight_init</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">m</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.weight_init" title="Link to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Usage:</dt><dd><p>model = Model()
model.apply(weight_init)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dsipts.models.utils.weight_init_zeros">
<span class="sig-prename descclassname"><span class="pre">dsipts.models.utils.</span></span><span class="sig-name descname"><span class="pre">weight_init_zeros</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">m</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dsipts.models.utils.weight_init_zeros" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="module-dsipts.models">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-dsipts.models" title="Link to this heading">¶</a></h2>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">DSIPTS</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api.html">API Reference</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.2.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
      |
      <a href="_sources/dsipts.models.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>